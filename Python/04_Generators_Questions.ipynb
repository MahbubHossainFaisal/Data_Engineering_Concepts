{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb24674b",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## 💡 **Before You Start**  \n",
    "In **data engineering**, generators are used because:  \n",
    "- Data is often too large to fit in memory.  \n",
    "- Lazy evaluation saves time and resources.  \n",
    "- Clean code that behaves like a pipeline.\n",
    "\n",
    "---\n",
    "\n",
    "## 🏁 **Level 1: Beginner — Fundamental Generator Usage**  \n",
    "\n",
    "---\n",
    "\n",
    "### 🧑‍💻 **Q1: Generate Numbers 1 to N**\n",
    "\n",
    "**Task:**  \n",
    "Write a generator function `generate_numbers(n)` that yields numbers from `1` to `n` one by one.\n",
    "\n",
    "💡 **Why:** This mirrors scenarios like streaming row IDs or sequential event timestamps.\n",
    "\n",
    "**Example:**\n",
    "```python\n",
    "gen = generate_numbers(5)\n",
    "print(list(gen))  # Output: [1, 2, 3, 4, 5]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 🧑‍💻 **Q2: Infinite Even Number Stream**\n",
    "\n",
    "**Task:**  \n",
    "Create a generator `generate_even_numbers()` that produces an **infinite sequence of even numbers** starting from `2`. Stop iteration must be controlled from the consumer side.\n",
    "\n",
    "💡 **Why:** Many data systems process streaming data with unknown size, and generators fit perfectly.\n",
    "\n",
    "**Example:**\n",
    "```python\n",
    "gen = generate_even_numbers()\n",
    "for _ in range(5):\n",
    "    print(next(gen), end=' ')  # Output: 2 4 6 8 10\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 🧑‍💻 **Q3: Square Values of a List**\n",
    "\n",
    "**Task:**  \n",
    "Write a generator `square_numbers(lst)` that takes a list of numbers and lazily yields their squares.\n",
    "\n",
    "💡 **Why:** Mimics data transformation pipelines — e.g., normalizing numerical fields.\n",
    "\n",
    "**Example:**\n",
    "```python\n",
    "lst = [1, 2, 3, 4]\n",
    "gen = square_numbers(lst)\n",
    "print(list(gen))  # Output: [1, 4, 9, 16]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 🧑‍💻 **Q4: Chunk a Large Dataset**\n",
    "\n",
    "**Task:**  \n",
    "Write a generator `chunker(iterable, chunk_size)` that splits large data into smaller chunks of size `chunk_size`.\n",
    "\n",
    "💡 **Why:** Chunking is fundamental for batch processing — Snowflake, S3, GCS, Kafka all use this.\n",
    "\n",
    "**Example:**\n",
    "```python\n",
    "lst = [1, 2, 3, 4, 5, 6, 7]\n",
    "gen = chunker(lst, 3)\n",
    "for chunk in gen:\n",
    "    print(chunk)  # Output: [1,2,3], [4,5,6], [7]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 🧑‍💻 **Q5: CSV Row Reader**\n",
    "\n",
    "**Task:**  \n",
    "Write a generator `read_csv(file_path)` that reads a CSV file line by line, yielding each row as a list.\n",
    "\n",
    "💡 **Why:**  \n",
    "When dealing with huge files like logs or transaction records, you never want to load the whole file into memory.\n",
    "\n",
    "**Example:**\n",
    "```python\n",
    "# Suppose file content is:\n",
    "# John,30,NY\n",
    "# Alice,25,LA\n",
    "\n",
    "gen = read_csv('users.csv')\n",
    "print(next(gen))  # Output: ['John', '30', 'NY']\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ⚡️ **Level 2: Intermediate — Transformation & Filtering**\n",
    "\n",
    "---\n",
    "\n",
    "### 🧑‍💻 **Q6: Filter Positive Numbers**\n",
    "\n",
    "**Task:**  \n",
    "Write a generator `filter_positive_numbers(numbers)` that yields only **positive integers** from a given list.\n",
    "\n",
    "💡 **Why:** Filtering raw data before further processing saves compute and network.\n",
    "\n",
    "**Example:**\n",
    "```python\n",
    "lst = [-1, 4, -2, 5, 0]\n",
    "gen = filter_positive_numbers(lst)\n",
    "print(list(gen))  # Output: [4, 5]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 🧑‍💻 **Q7: Paginated API Simulation**\n",
    "\n",
    "**Task:**  \n",
    "Create a generator `mock_api_paginator(data_list, page_size)` that yields one \"page\" at a time from a list.\n",
    "\n",
    "💡 **Why:** APIs like AWS S3 or BigQuery use pagination when the result set is too large.\n",
    "\n",
    "**Example:**\n",
    "```python\n",
    "data = list(range(1, 11))\n",
    "gen = mock_api_paginator(data, 4)\n",
    "print(next(gen))  # Output: [1, 2, 3, 4]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 🧑‍💻 **Q8: Infinite Fibonacci Sequence**\n",
    "\n",
    "**Task:**  \n",
    "Write `fibonacci_sequence()` — a generator that yields an infinite Fibonacci series:  \n",
    "`0, 1, 1, 2, 3, 5, 8, ...`\n",
    "\n",
    "💡 **Why:** Lazy evaluation is key when the end of the series is unknown.\n",
    "\n",
    "---\n",
    "\n",
    "### 🧑‍💻 **Q9: Unique ID Generator**\n",
    "\n",
    "**Task:**  \n",
    "Write `unique_id_generator(prefix)` that yields:  \n",
    "`prefix_1, prefix_2, prefix_3...`\n",
    "\n",
    "💡 **Why:** Used to create synthetic primary keys or filenames.\n",
    "\n",
    "---\n",
    "\n",
    "### 🧑‍💻 **Q10: Date Range Generator**\n",
    "\n",
    "**Task:**  \n",
    "Write `date_range(start_date, end_date)` that yields every date from `start` to `end`.\n",
    "\n",
    "💡 **Why:** Generating date partitions for data lake queries or backfilling.\n",
    "\n",
    "**Example:**\n",
    "```python\n",
    "from datetime import date\n",
    "gen = date_range(date(2024, 1, 1), date(2024, 1, 4))\n",
    "print(list(gen))  \n",
    "# Output: [2024-01-01, 2024-01-02, 2024-01-03, 2024-01-04]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 🚀 **Level 3: Advanced — Real-World Streaming & Patterns**\n",
    "\n",
    "---\n",
    "\n",
    "### 🧑‍💻 **Q11: Sliding Window over a Sequence**\n",
    "\n",
    "**Task:**  \n",
    "Write `sliding_window(sequence, window_size)` that yields overlapping sublists (windows).\n",
    "\n",
    "💡 **Why:** Used in **time-series anomaly detection** and **rolling averages**.\n",
    "\n",
    "**Example:**\n",
    "```python\n",
    "gen = sliding_window([1, 2, 3, 4, 5], 3)\n",
    "# Output: [1,2,3], [2,3,4], [3,4,5]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 🧑‍💻 **Q12: Apply Transformation to a Stream**\n",
    "\n",
    "**Task:**  \n",
    "Write `apply_transformation(generator, func)` to yield `func(item)` for every item in the input generator.\n",
    "\n",
    "💡 **Why:** Fundamental for transformation stages in ETL pipelines.\n",
    "\n",
    "---\n",
    "\n",
    "### 🧑‍💻 **Q13: Flatten Nested Lists**\n",
    "\n",
    "**Task:**  \n",
    "Write `flatten(nested_list)` that flattens nested lists:  \n",
    "Example: `[[1, 2], [3, 4]]` → `1, 2, 3, 4`\n",
    "\n",
    "💡 **Why:** Flattening nested records for schema normalization.\n",
    "\n",
    "---\n",
    "\n",
    "### 🧑‍💻 **Q14: Log File Tailer**\n",
    "\n",
    "**Task:**  \n",
    "Write `tail(file_path)` that watches a log file and yields new lines as they are written.\n",
    "\n",
    "💡 **Why:** Log monitoring without loading entire files — similar to `tail -f`.\n",
    "\n",
    "---\n",
    "\n",
    "### 🧑‍💻 **Q15: Build Generator Pipelines**\n",
    "\n",
    "**Task:**  \n",
    "Design a sequence of generators where each generator processes the output of the previous one, e.g.:  \n",
    "- Generator1: reads lines from a file.  \n",
    "- Generator2: filters valid JSON lines.  \n",
    "- Generator3: extracts fields.\n",
    "\n",
    "💡 **Why:** Used in ETL pipelines, Kafka consumers, and Spark-like frameworks.\n",
    "\n",
    "---\n",
    "\n",
    "## 🔥 **Level 4: Expert — Handling Exhaustion, Reuse & Streaming Challenges**\n",
    "\n",
    "---\n",
    "\n",
    "### 🧑‍💻 **Q16: Generator Class Implementation**\n",
    "\n",
    "**Task:**  \n",
    "Implement a generator using an iterator class with `__iter__` and `__next__`.\n",
    "\n",
    "💡 **Why:** Understand the difference between **generator function** and **iterator class**.\n",
    "\n",
    "---\n",
    "\n",
    "### 🧑‍💻 **Q17: Random Sampler Without Repeats**\n",
    "\n",
    "**Task:**  \n",
    "Write a generator `random_sampler(data)` that randomly yields items from a list, without repeating, until all items are exhausted.\n",
    "\n",
    "💡 **Why:** Sampling subsets from large datasets for testing or training.\n",
    "\n",
    "---\n",
    "\n",
    "### 🧑‍💻 **Q18: Merge Two Sorted Generators**\n",
    "\n",
    "**Task:**  \n",
    "Write `merge_sorted_streams(gen1, gen2)` that lazily merges two sorted generators.\n",
    "\n",
    "💡 **Why:** Useful when merging two log files or two sorted data streams.\n",
    "\n",
    "---\n",
    "\n",
    "### 🧑‍💻 **Q19: Read File with Backpressure Simulation**\n",
    "\n",
    "**Task:**  \n",
    "Simulate a generator `read_file_in_chunks(file_path, chunk_size)` that can pause/resume based on consumer signals (simulate \"backpressure\").\n",
    "\n",
    "💡 **Why:** Mimics real-world systems like Apache Kafka and Airflow operators which throttle data consumption.\n",
    "\n",
    "---\n",
    "\n",
    "### 🧑‍💻 **Q20: Mini Data Pipeline Simulation**\n",
    "\n",
    "**Task:**  \n",
    "Create a full data pipeline using generators:\n",
    "- Stage 1: read CSV.\n",
    "- Stage 2: filter rows.\n",
    "- Stage 3: transform data.\n",
    "- Stage 4: output results.\n",
    "\n",
    "💡 **Why:** This is how data flows in real-world ETL jobs.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4c6348",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
