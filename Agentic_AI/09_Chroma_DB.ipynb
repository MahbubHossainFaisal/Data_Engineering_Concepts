{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ccde3f13",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## üß† What is ChromaDB?\n",
    "\n",
    "**ChromaDB** is an open-source **vector database** built for **AI-native applications**. It stores **embeddings** (vector representations of data like text, images, etc.) along with **metadata**, and allows **fast similarity search**.\n",
    "\n",
    "It‚Äôs one of the most **developer-friendly vector stores**, with **local persistence**, **simple APIs**, and **tight LangChain integration**.\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Purpose of ChromaDB in GenAI Pipelines\n",
    "\n",
    "* Converts text into **embeddings** using a model (like OpenAI).\n",
    "* Stores those vectors with **associated metadata and documents**.\n",
    "* Allows **semantic search** (similarity-based retrieval).\n",
    "* Serves as the **retriever backend** for **RAG** (Retrieval-Augmented Generation).\n",
    "\n",
    "‚úÖ It's used when you want a **fast, local, minimal-setup** solution for storing and querying vectorized documents.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚öñÔ∏è ChromaDB vs. FAISS ‚Äì Key Differences\n",
    "\n",
    "| Feature          | **ChromaDB**                      | **FAISS**                             |\n",
    "| ---------------- | --------------------------------- | ------------------------------------- |\n",
    "| Type             | Vector **database**               | Vector **index/search library**       |\n",
    "| Persistence      | Built-in                          | Manual (must save to disk explicitly) |\n",
    "| Metadata Support | Native support                    | Manual (requires parallel storage)    |\n",
    "| Filters          | Yes (built-in metadata filtering) | No (requires custom code)             |\n",
    "| Setup            | Easy (single pip install)         | More control, but manual              |\n",
    "| Use Case         | Ideal for prototyping, local RAG  | High performance, large-scale apps    |\n",
    "\n",
    "‚úÖ If you want **fast dev loop + metadata + persistence** ‚Üí use ChromaDB\n",
    "‚úÖ If you want **blazing fast control on indexing and search** ‚Üí use FAISS\n",
    "\n",
    "---\n",
    "\n",
    "## üìå Important Parameters of ChromaDB Vector Store\n",
    "\n",
    "When initializing or using ChromaDB via LangChain:\n",
    "\n",
    "```python\n",
    "Chroma(\n",
    "    collection_name=\"my_docs\",\n",
    "    embedding_function=OpenAIEmbeddings(),\n",
    "    persist_directory=\"db\"\n",
    ")\n",
    "```\n",
    "\n",
    "### Key Parameters:\n",
    "\n",
    "| Parameter            | Description                                     |\n",
    "| -------------------- | ----------------------------------------------- |\n",
    "| `collection_name`    | Name of the ChromaDB collection                 |\n",
    "| `embedding_function` | Embedding model used to encode texts            |\n",
    "| `persist_directory`  | Local directory to save DB for reuse            |\n",
    "| `client_settings`    | Custom settings like number of threads, timeout |\n",
    "| `metadata`           | Key-value pairs like `{\"source\": \"file1.txt\"}`  |\n",
    "\n",
    "---\n",
    "\n",
    "## üßÆ Similarity and Score Feature in ChromaDB\n",
    "\n",
    "* ChromaDB uses **cosine similarity** by default.\n",
    "* Score ranges from **0 (no match)** to **1 (exact match)**.\n",
    "* During retrieval, you get tuples of `(Document, score)`.\n",
    "\n",
    "```python\n",
    "docs = retriever.similarity_search_with_score(\"quantum computing\", k=3)\n",
    "for doc, score in docs:\n",
    "    print(score)  # Example: 0.83, 0.77, ...\n",
    "```\n",
    "\n",
    "‚úÖ Scores help with **ranking**, **thresholding**, or **reranking with LLMs**.\n",
    "\n",
    "---\n",
    "\n",
    "## üîÑ How to Use ChromaDB as a Retriever ‚Äî Full Example\n",
    "\n",
    "Here‚Äôs a full LangChain pipeline:\n",
    "\n",
    "### üì¶ Step 1: Install dependencies\n",
    "\n",
    "```bash\n",
    "pip install chromadb langchain openai\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### üìò Step 2: Load and Split Documents\n",
    "\n",
    "```python\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "loader = TextLoader(\"your_text.txt\")\n",
    "docs = loader.load()\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "chunks = splitter.split_documents(docs)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### üß† Step 3: Create Embeddings and Store in ChromaDB\n",
    "\n",
    "```python\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "embedding_fn = OpenAIEmbeddings()\n",
    "\n",
    "vectordb = Chroma.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=embedding_fn,\n",
    "    persist_directory=\"chroma_db\",\n",
    "    collection_name=\"my_collection\"\n",
    ")\n",
    "\n",
    "vectordb.persist()  # Save DB to disk\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### üîç Step 4: Query ChromaDB\n",
    "\n",
    "```python\n",
    "retriever = vectordb.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})\n",
    "\n",
    "results = retriever.get_relevant_documents(\"What is quantum physics?\")\n",
    "\n",
    "for doc in results:\n",
    "    print(doc.page_content)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üíæ Saving and Loading ChromaDB\n",
    "\n",
    "### ‚úÖ Saving (already done with `.persist()`):\n",
    "\n",
    "```python\n",
    "vectordb.persist()\n",
    "```\n",
    "\n",
    "### üîÑ Loading from disk later:\n",
    "\n",
    "```python\n",
    "vectordb = Chroma(\n",
    "    persist_directory=\"chroma_db\",\n",
    "    embedding_function=OpenAIEmbeddings(),\n",
    "    collection_name=\"my_collection\"\n",
    ")\n",
    "```\n",
    "\n",
    "You can now continue retrieving documents or adding new ones.\n",
    "\n",
    "---\n",
    "\n",
    "## üß† Important Parameters in Local Load of ChromaDB\n",
    "\n",
    "```python\n",
    "Chroma(\n",
    "    persist_directory=\"chroma_db\",\n",
    "    collection_name=\"my_collection\",\n",
    "    embedding_function=OpenAIEmbeddings()\n",
    ")\n",
    "```\n",
    "\n",
    "| Parameter            | Purpose                                  |\n",
    "| -------------------- | ---------------------------------------- |\n",
    "| `persist_directory`  | Path to local folder storing the DB      |\n",
    "| `collection_name`    | Ensure same name as when saved           |\n",
    "| `embedding_function` | Required to match embeddings and queries |\n",
    "\n",
    "‚ö†Ô∏è Make sure the same `embedding_function` is used to **maintain embedding space consistency**!\n",
    "\n",
    "---\n",
    "\n",
    "## üíº Important Questions\n",
    "\n",
    "1. **What are the trade-offs between ChromaDB and FAISS?**\n",
    "2. **How does ChromaDB handle similarity search?**\n",
    "3. **Can you filter documents in ChromaDB by metadata?**\n",
    "4. **How would you reload an existing ChromaDB vector store?**\n",
    "5. **How does ChromaDB ensure persistent local storage?**\n",
    "6. **What happens if you use different embedding models for query and documents?**\n",
    "7. **How would you update or delete documents from ChromaDB?**\n",
    "8. **How is chunking important before inserting into ChromaDB?**\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925ee1f9",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### üîπ **1. What are the trade-offs between ChromaDB and FAISS?**\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "| Feature            | ChromaDB                                     | FAISS                                        |\n",
    "| ------------------ | -------------------------------------------- | -------------------------------------------- |\n",
    "| Type               | Vector database with persistence             | Vector search library                        |\n",
    "| Metadata           | Native support for metadata                  | No native metadata support                   |\n",
    "| Filtering          | Supports filtering via metadata              | Not natively supported                       |\n",
    "| Storage            | Built-in local persistence (via `persist()`) | Must manually serialize and deserialize      |\n",
    "| API Simplicity     | Very developer-friendly (higher-level APIs)  | Requires more boilerplate and setup          |\n",
    "| Scale              | Best for local, dev-scale workloads          | Optimized for large-scale, production search |\n",
    "| Distributed Search | Not yet supported (single-node)              | Requires extensions to support distributed   |\n",
    "\n",
    "**Trade-off Summary:**\n",
    "ChromaDB is **great for local dev and RAG prototyping**, but FAISS offers **better control and raw performance** at scale.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ **2. How does ChromaDB handle similarity search?**\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "ChromaDB performs **vector similarity search** using **cosine similarity** by default. This compares the angle between two high-dimensional vectors (query and document), making it scale-invariant.\n",
    "\n",
    "* Score = cosine similarity ‚àà \\[0, 1]\n",
    "* You query with an embedding vector and Chroma returns documents ranked by score.\n",
    "\n",
    "```python\n",
    "retriever = vectordb.as_retriever()\n",
    "results = retriever.get_relevant_documents(\"What is AI?\")\n",
    "```\n",
    "\n",
    "It uses **approximate nearest neighbor (ANN)** methods under the hood for performance.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ **3. Can you filter documents in ChromaDB by metadata?**\n",
    "\n",
    "**Answer: Yes.**\n",
    "\n",
    "ChromaDB supports **metadata filtering** on vector search:\n",
    "\n",
    "```python\n",
    "retriever = vectordb.as_retriever(\n",
    "    search_kwargs={\n",
    "        \"k\": 3,\n",
    "        \"filter\": {\"source\": \"notes.txt\"}\n",
    "    }\n",
    ")\n",
    "```\n",
    "\n",
    "This allows hybrid filtering ‚Äî **semantic + metadata** filtering at the same time. It's very useful when you have many documents with different contexts (e.g., source, author, topic).\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ **4. How would you reload an existing ChromaDB vector store?**\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "To reload an existing ChromaDB vector store (e.g., across app runs):\n",
    "\n",
    "```python\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "vectordb = Chroma(\n",
    "    persist_directory=\"chroma_db\",\n",
    "    collection_name=\"my_collection\",\n",
    "    embedding_function=OpenAIEmbeddings()\n",
    ")\n",
    "```\n",
    "\n",
    "‚ùó `collection_name` and `embedding_function` **must match** the ones used during persistence.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ **5. How does ChromaDB ensure persistent local storage?**\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "ChromaDB uses **SQLite** and **binary blob storage** to persist vectors and metadata locally.\n",
    "\n",
    "* When you call `.persist()`, ChromaDB saves:\n",
    "\n",
    "  * Collection config\n",
    "  * Document metadata\n",
    "  * Vector embeddings\n",
    "\n",
    "You can specify the location using `persist_directory=\"my_folder\"`.\n",
    "\n",
    "This enables you to reuse the vector store across sessions or deployments.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ **6. What happens if you use different embedding models for query and documents?**\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "‚ùå It will **break the semantic consistency**.\n",
    "\n",
    "* Each embedding model has its own **vector space**.\n",
    "* If your documents were embedded using `OpenAI` and you query using `HuggingFace`, the cosine similarity won't be meaningful.\n",
    "\n",
    "**Best Practice:** Always use the **same embedding function** (same model, version, and tokenizer) for indexing and querying.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ **7. How would you update or delete documents from ChromaDB?**\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "LangChain's integration with ChromaDB currently supports adding new documents but **doesn't have direct APIs for deletion or update**.\n",
    "\n",
    "However, using raw ChromaDB APIs, you can do:\n",
    "\n",
    "```python\n",
    "# Use Chroma's lower-level client\n",
    "import chromadb\n",
    "client = chromadb.PersistentClient(path=\"chroma_db\")\n",
    "collection = client.get_collection(\"my_collection\")\n",
    "\n",
    "collection.delete(\n",
    "    where={\"source\": \"notes.txt\"}  # metadata filter\n",
    ")\n",
    "```\n",
    "\n",
    "‚úÖ For updates: delete + re-insert the document.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ **8. How is chunking important before inserting into ChromaDB?**\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "**Chunking (using text splitters)** helps in:\n",
    "\n",
    "* Keeping each chunk **small enough to embed meaningfully** (e.g., 500 tokens).\n",
    "* Improving **semantic retrieval** by narrowing the scope of each document.\n",
    "* Ensuring the LLM receives **focused, context-rich content** during RAG.\n",
    "\n",
    "Tools like `RecursiveCharacterTextSplitter` ensure splits happen at **logical boundaries** (paragraphs ‚Üí sentences ‚Üí words), improving quality.\n",
    "\n",
    "Example:\n",
    "\n",
    "```python\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=50\n",
    ")\n",
    "\n",
    "chunks = splitter.split_documents(docs)\n",
    "```\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf32d25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
