{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a404a4a2",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## üîπ 1. What is FAISS?\n",
    "\n",
    "**FAISS (Facebook AI Similarity Search)** is an **open-source library** developed by Meta AI that enables:\n",
    "\n",
    "* **Efficient similarity search**,\n",
    "* **Clustering** of **dense vectors**,\n",
    "* At **scale** and with **high performance**.\n",
    "\n",
    "üëâ It‚Äôs optimized for:\n",
    "\n",
    "* **Fast nearest neighbor search** in **large-scale datasets**\n",
    "* Using **CPU** or **GPU**\n",
    "\n",
    "---\n",
    "\n",
    "## üîπ 2. Purpose of FAISS\n",
    "\n",
    "The **primary goal** of FAISS is to **quickly find similar vectors** from a **large corpus**.\n",
    "\n",
    "üß† In Gen AI systems, we use FAISS for:\n",
    "\n",
    "* **Semantic search** (e.g., retrieve relevant documents for a question)\n",
    "* **RAG** pipelines (retrieve ‚Üí augment prompt ‚Üí generate)\n",
    "* Fast **similarity matching** (e.g., recommendations)\n",
    "\n",
    "---\n",
    "\n",
    "## üîπ 3. Important Parameters of FAISS Vector Store\n",
    "\n",
    "Let‚Äôs look at FAISS from **LangChain‚Äôs abstraction**, where FAISS is used as a **retriever** or **vector store**.\n",
    "\n",
    "### üí° Core Parameters:\n",
    "\n",
    "| Parameter            | Description                                                                  |\n",
    "| -------------------- | ---------------------------------------------------------------------------- |\n",
    "| `embedding_function` | Function that turns text into vector (e.g., `OpenAIEmbeddings`)              |\n",
    "| `index`              | FAISS index (e.g., `IndexFlatL2`, `IndexFlatIP`, `IndexIVFFlat`)             |\n",
    "| `normalize_L2`       | Whether to normalize vectors before adding (important for cosine similarity) |\n",
    "| `metadatas`          | Metadata attached to vectors (e.g., source, page no.)                        |\n",
    "| `documents`          | Original text chunks or content                                              |\n",
    "| `distance_metric`    | Metric used (`L2`, `cosine`, `inner product`)                                |\n",
    "\n",
    "---\n",
    "\n",
    "## üîπ 4. FAISS Similarity with Score Feature\n",
    "\n",
    "By default, **FAISS returns nearest vectors**, but with `similarity_search_with_score`, it returns:\n",
    "\n",
    "```python\n",
    "[(Document, score), (Document, score), ...]\n",
    "```\n",
    "\n",
    "### üìå Score Meaning:\n",
    "\n",
    "* **L2 index (IndexFlatL2)**: Lower score means **more similar** (since it's a distance).\n",
    "* **Cosine similarity or Dot Product**: Higher score means **more similar**.\n",
    "\n",
    "‚úÖ You must **interpret score based on index type**.\n",
    "\n",
    "---\n",
    "\n",
    "## üîπ 5. How to Use FAISS as a Retriever (with Code)\n",
    "\n",
    "### ‚úÖ Step-by-Step Example\n",
    "\n",
    "```python\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# 1. Load documents\n",
    "loader = TextLoader(\"example.txt\")\n",
    "docs = loader.load()\n",
    "\n",
    "# 2. Split documents\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "chunks = splitter.split_documents(docs)\n",
    "\n",
    "# 3. Create embeddings\n",
    "embedding = OpenAIEmbeddings()\n",
    "\n",
    "# 4. Create FAISS vector store\n",
    "faiss_store = FAISS.from_documents(chunks, embedding)\n",
    "\n",
    "# 5. Use as retriever\n",
    "retriever = faiss_store.as_retriever()\n",
    "\n",
    "# 6. Search with query\n",
    "query = \"What is FAISS used for?\"\n",
    "results = retriever.get_relevant_documents(query)\n",
    "\n",
    "for doc in results:\n",
    "    print(doc.page_content)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üîπ 6. Saving and Loading FAISS Vector Store\n",
    "\n",
    "This is **important** for reusability and performance in production.\n",
    "\n",
    "### ‚úÖ Saving\n",
    "\n",
    "```python\n",
    "faiss_store.save_local(\"faiss_index\")\n",
    "```\n",
    "\n",
    "This saves:\n",
    "\n",
    "* Vector index (`index.faiss`)\n",
    "* Document store + metadata (`index.pkl`)\n",
    "\n",
    "### ‚úÖ Loading\n",
    "\n",
    "```python\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "# Load from disk\n",
    "loaded_store = FAISS.load_local(\"faiss_index\", embeddings=embedding)\n",
    "\n",
    "# Test search\n",
    "results = loaded_store.similarity_search(\"What is FAISS?\", k=3)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üîπ 7. Important Parameters in Local Load\n",
    "\n",
    "```python\n",
    "FAISS.load_local(folder_path, embeddings, index_name=\"index\", normalize_L2=False)\n",
    "```\n",
    "\n",
    "| Parameter      | Description                                                         |\n",
    "| -------------- | ------------------------------------------------------------------- |\n",
    "| `folder_path`  | Directory where `index.faiss` and `index.pkl` are stored            |\n",
    "| `embeddings`   | Embedding function to convert queries to vectors                    |\n",
    "| `index_name`   | Name prefix of saved files. (e.g., \"index\" ‚Üí loads `index.faiss`)   |\n",
    "| `normalize_L2` | If True, normalizes vectors during loading (for cosine similarity). |\n",
    "\n",
    "### ‚úÖ Example with Normalization\n",
    "\n",
    "```python\n",
    "FAISS.load_local(\"faiss_index\", embeddings=embedding, normalize_L2=True)\n",
    "```\n",
    "\n",
    "Use this if your retrieval is **cosine-based**.\n",
    "\n",
    "---\n",
    "\n",
    "## üîπ Bonus: IMPORTANT Questions (Must-Know)\n",
    "\n",
    "1. **What is FAISS and why is it useful in GenAI pipelines?**\n",
    "2. **Difference between IndexFlatL2 and IndexFlatIP in FAISS?**\n",
    "3. **When would you normalize vectors in FAISS and why?**\n",
    "4. **How does FAISS handle cosine similarity if it‚Äôs distance-based?**\n",
    "5. **How would you scale FAISS to millions of vectors?**\n",
    "6. **How does FAISS compare to Chroma or Pinecone?**\n",
    "7. **What are pros and cons of using FAISS for local vs. cloud vector storage?**\n",
    "8. **Explain how FAISS works under the hood with ANN (Approximate Nearest Neighbors)?**\n",
    "9. **How would you update or delete documents from a FAISS index?**\n",
    "10. **Why is it necessary to store metadata with embeddings in FAISS for GenAI?**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8fb440",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ 1. **What is FAISS and why is it useful in GenAI pipelines?**\n",
    "\n",
    "**Answer:**\n",
    "FAISS (Facebook AI Similarity Search) is an open-source vector similarity library built by Meta. It allows **fast and scalable nearest-neighbor search** on **dense vector representations** (embeddings).\n",
    "\n",
    "In GenAI pipelines:\n",
    "\n",
    "* It's used to **store and search document embeddings**.\n",
    "* Enables **semantic search** by finding text chunks **most similar** to a user query vector.\n",
    "* It's essential in **RAG (Retrieval-Augmented Generation)** for grounding large language models on domain-specific data.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ 2. **Difference between `IndexFlatL2` and `IndexFlatIP` in FAISS?**\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "| Index         | Metric                  | Similarity Logic                  | Use Case                                                            |\n",
    "| ------------- | ----------------------- | --------------------------------- | ------------------------------------------------------------------- |\n",
    "| `IndexFlatL2` | L2 Distance (Euclidean) | Lower distance = more similar     | General similarity search                                           |\n",
    "| `IndexFlatIP` | Inner Product           | Higher dot product = more similar | When embeddings are normalized or cosine similarity is approximated |\n",
    "\n",
    "üìå If embeddings are **normalized**, inner product ‚âà **cosine similarity**, so `IndexFlatIP` can be used for **cosine-based** retrieval.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ 3. **When would you normalize vectors in FAISS and why?**\n",
    "\n",
    "**Answer:**\n",
    "You normalize vectors **when you want to use cosine similarity** instead of Euclidean distance.\n",
    "\n",
    "* Cosine similarity = dot product of **unit vectors**.\n",
    "* FAISS does not directly support cosine similarity, so we **approximate it** by:\n",
    "\n",
    "  * Normalizing all vectors to unit length (L2 norm = 1)\n",
    "  * Using `IndexFlatIP`\n",
    "\n",
    "‚úÖ This is necessary when **semantic closeness** matters more than magnitude.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ 4. **How does FAISS handle cosine similarity if it‚Äôs distance-based?**\n",
    "\n",
    "**Answer:**\n",
    "FAISS doesn‚Äôt natively support cosine similarity. But cosine similarity can be **approximated** using **inner product (dot product)** **after normalization**.\n",
    "\n",
    "üîÅ Steps:\n",
    "\n",
    "1. Normalize all vectors to unit norm.\n",
    "2. Use `IndexFlatIP` (inner product).\n",
    "3. The inner product becomes equivalent to cosine similarity.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ 5. **How would you scale FAISS to millions of vectors?**\n",
    "\n",
    "**Answer:**\n",
    "For large-scale vector search (millions+):\n",
    "\n",
    "1. **Use Approximate Nearest Neighbor (ANN) indexes** like:\n",
    "\n",
    "   * `IndexIVFFlat` (inverted index)\n",
    "   * `IndexHNSWFlat` (Hierarchical Navigable Small World)\n",
    "   * `IndexIVFPQ` (product quantization)\n",
    "\n",
    "2. **Pre-train** the index:\n",
    "\n",
    "   * With `train()` method using sample vectors (required for IVF, PQ).\n",
    "\n",
    "3. Use **GPU support** with `faiss-gpu`.\n",
    "\n",
    "4. **Sharding and batching** if data is massive.\n",
    "\n",
    "‚úÖ Trade-off: Slight drop in accuracy, but huge gain in **performance and memory usage**.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ 6. **How does FAISS compare to Chroma or Pinecone?**\n",
    "\n",
    "| Feature     | FAISS                  | ChromaDB               | Pinecone              |\n",
    "| ----------- | ---------------------- | ---------------------- | --------------------- |\n",
    "| Hosting     | Local/in-memory        | Local/Serverless       | Cloud SaaS            |\n",
    "| Scaling     | Manual                 | Medium (dev-focused)   | High (Auto-scalable)  |\n",
    "| ANN support | Yes (advanced)         | Yes (basic)            | Yes                   |\n",
    "| Integration | LangChain, HuggingFace | LangChain, LlamaIndex  | LangChain, LlamaIndex |\n",
    "| Use Case    | Custom, control-heavy  | Lightweight prototypes | Production, scalable  |\n",
    "\n",
    "‚úÖ Use **FAISS** when:\n",
    "\n",
    "* You want **full control**, **no internet**, and **fast prototyping**.\n",
    "  ‚úÖ Use **Pinecone** for **enterprise**, **distributed**, or **multi-tenant** applications.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ 7. **What are pros and cons of using FAISS for local vs. cloud vector storage?**\n",
    "\n",
    "| Criteria   | FAISS (Local)                 | Cloud (Pinecone, Weaviate, etc.) |\n",
    "| ---------- | ----------------------------- | -------------------------------- |\n",
    "| ‚úÖ Pros     | Fast, no network, open-source | Scalable, distributed, easy APIs |\n",
    "| ‚ùå Cons     | Manual scaling, no multi-node | Costly, limited local control    |\n",
    "| ‚úÖ Use Case | Prototyping, offline systems  | Multi-user GenAI apps, RAG APIs  |\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ 8. **Explain how FAISS works under the hood with ANN (Approximate Nearest Neighbors)?**\n",
    "\n",
    "**Answer:**\n",
    "FAISS provides **ANN search algorithms** like IVF, HNSW, PQ:\n",
    "\n",
    "1. **IVF (Inverted File Index)**:\n",
    "\n",
    "   * Clusters vectors into `n` groups (like k-means).\n",
    "   * Searches only relevant clusters.\n",
    "\n",
    "2. **HNSW (Graph-based)**:\n",
    "\n",
    "   * Builds a navigable small-world graph.\n",
    "   * Traverses nodes to find nearest neighbors.\n",
    "\n",
    "3. **PQ (Product Quantization)**:\n",
    "\n",
    "   * Compresses vectors to reduce memory.\n",
    "   * Approximate vector comparison.\n",
    "\n",
    "‚úÖ These indexes dramatically **reduce query time** and **memory cost**, enabling search across millions of vectors.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ 9. **How would you update or delete documents from a FAISS index?**\n",
    "\n",
    "**Answer:**\n",
    "FAISS **does not support in-place deletion or updates**.\n",
    "\n",
    "üß† Workarounds:\n",
    "\n",
    "* Maintain a **mapping between index ID and documents**.\n",
    "* Mark entries as **\"deleted\"** via metadata filtering.\n",
    "* Periodically **rebuild the index** with updated documents.\n",
    "\n",
    "LangChain helps by tracking documents in the `index.pkl` file, where you can **reconstruct the store**.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ 10. **Why is it necessary to store metadata with embeddings in FAISS for GenAI?**\n",
    "\n",
    "**Answer:**\n",
    "Storing metadata is **critical** because:\n",
    "\n",
    "* Embeddings alone are meaningless‚Äîmetadata helps trace back to:\n",
    "\n",
    "  * **Original text**\n",
    "  * **Document source**\n",
    "  * **Page number**\n",
    "  * **Timestamp or author**\n",
    "* Enables **filtering**, **reranking**, and **contextual generation** in RAG pipelines.\n",
    "\n",
    "‚úÖ Without metadata, you can‚Äôt effectively use the results from vector search in a production system.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5672943c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
