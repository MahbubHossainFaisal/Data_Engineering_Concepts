{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0118f235",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## 🧠 **1. What is LangGraph? (Definition in Detail)**\n",
    "\n",
    "### 📘 **Definition**:\n",
    "\n",
    "**LangGraph** is a **Python library** used to build **stateful, multi-actor applications** using **Large Language Models (LLMs)**. It does this by using the concept of a **graph**, where each node represents a function (like calling an LLM, saving memory, or invoking a human), and the edges represent transitions based on the state/output.\n",
    "\n",
    "Think of LangGraph as a **flowchart** where every step can involve a smart AI (LLM), and the flow can remember past steps (stateful).\n",
    "\n",
    "---\n",
    "\n",
    "## ✨ **2. Key Features of LangGraph**\n",
    "\n",
    "| Feature                         | Description                                                                                                              |\n",
    "| ------------------------------- | ------------------------------------------------------------------------------------------------------------------------ |\n",
    "| ✅ **Stateful Execution**        | Each run maintains a state that changes as the graph progresses. Useful for chatbots, agents, or any app needing memory. |\n",
    "| 🔄 **Dynamic Flow Control**     | Decisions in the flow can be made **at runtime** based on the state or LLM output.                                       |\n",
    "| 👥 **Multi-Actor Architecture** | Multiple \"actors\" (like agents or humans) can participate in the graph and pass control between each other.              |\n",
    "| 🧩 **Modular Graph Design**     | Each node is a reusable function — plug & play.                                                                          |\n",
    "| 💾 **Memory Integration**       | Built-in support for LangChain Memory modules to carry state and conversation history.                                   |\n",
    "| 🧪 **Human-in-the-Loop (HITL)** | You can insert a human actor into the loop, ideal for approvals, escalations, or safety.                                 |\n",
    "| 🔌 **Easy LLM Integration**     | Direct support for OpenAI, Anthropic, and other models via LangChain.                                                    |\n",
    "| 📈 **Scalable and Reactive**    | Reacts to state changes and runs conditionally like dataflow engines.                                                    |\n",
    "\n",
    "---\n",
    "\n",
    "## 🧬 **3. How LangGraph is Inspired by Pregel and Apache Beam**\n",
    "\n",
    "LangGraph takes the **best of both worlds**:\n",
    "\n",
    "### 🐜 **Pregel** (Google's graph computation model):\n",
    "\n",
    "* Pregel is designed for **graph-parallel computation** (like analyzing social networks).\n",
    "* Each node can **send messages**, **receive messages**, and **update its own state**.\n",
    "* **LangGraph is similar** in that **each node represents a computation**, and **state changes over time** as it moves through the graph.\n",
    "\n",
    "### ⚙️ **Apache Beam**:\n",
    "\n",
    "* Apache Beam allows defining **data pipelines** that can run on multiple engines.\n",
    "* It's **reactive**, **event-driven**, and **state-aware**.\n",
    "* LangGraph takes this **reactivity** and **stateful design** into **LLM workflows**.\n",
    "\n",
    "👉 So, **LangGraph is Pregel + Apache Beam + LLMs** = 💡 Smart, reactive, multi-actor flows.\n",
    "\n",
    "---\n",
    "\n",
    "## 🎯 **4. What is LangGraph Built For?**\n",
    "\n",
    "LangGraph is built for:\n",
    "\n",
    "| Use Case                          | Description                                                |\n",
    "| --------------------------------- | ---------------------------------------------------------- |\n",
    "| 🤖 **Conversational Agents**      | LLMs that remember and respond across sessions.            |\n",
    "| 🧠 **Multi-step Reasoning Apps**  | Apps where LLMs think step-by-step.                        |\n",
    "| 🕵️‍♂️ **Multi-Agent Systems**    | Several LLMs or agents collaborating in a flow.            |\n",
    "| 🧍‍♂️ **Human-in-the-loop Flows** | Humans can pause, approve, edit, or influence the flow.    |\n",
    "| 🔁 **Stateful LLM Chains**        | Flows where state evolves and needs to be carried forward. |\n",
    "\n",
    "---\n",
    "\n",
    "## 🛠️ **5. What Problem Does LangGraph Solve?**\n",
    "\n",
    "### ✅ Problems Solved:\n",
    "\n",
    "1. ❌ LLMs are **stateless by default** – LangGraph adds **state**.\n",
    "2. ❌ Multi-agent collaboration is **hard to orchestrate** – LangGraph offers **graph-based control**.\n",
    "3. ❌ LLM workflows can be **linear and brittle** – LangGraph enables **dynamic and reactive flows**.\n",
    "4. ❌ Adding human decisions in workflows is tough – LangGraph makes **Human-in-the-loop** easy.\n",
    "5. ❌ No clear debugging/visual model – LangGraph makes logic **explicit and visualizable**.\n",
    "\n",
    "---\n",
    "\n",
    "## 🔁 **6. LangGraph is a Library for Building Stateful, Multi-Actor Applications with LLMs — In Depth**\n",
    "\n",
    "Let’s break this phrase into parts:\n",
    "\n",
    "### ✅ **Stateful**:\n",
    "\n",
    "The application maintains memory — like conversation history or user preferences. This means LangGraph apps can adapt over time.\n",
    "\n",
    "### ✅ **Multi-Actor**:\n",
    "\n",
    "There can be multiple participants:\n",
    "\n",
    "* Agents (LLMs)\n",
    "* Tools (like calculators)\n",
    "* Humans (approvers)\n",
    "  Each actor can process the state and pass it on.\n",
    "\n",
    "### ✅ **Applications with LLMs**:\n",
    "\n",
    "LangGraph is built on top of LangChain. Each node in the graph can use:\n",
    "\n",
    "* OpenAI\n",
    "* Anthropic\n",
    "* LangChain agents\n",
    "* Custom Python logic\n",
    "\n",
    "Think of a real-world use case:\n",
    "\n",
    "> A customer support bot that talks to users, invokes an expert LLM agent, brings in a human manager when stuck, and maintains full conversation history.\n",
    "\n",
    "---\n",
    "\n",
    "## 🧩 **7. LangGraph Components (Detailed)**\n",
    "\n",
    "| Component                    | Explanation                                                                                     |\n",
    "| ---------------------------- | ----------------------------------------------------------------------------------------------- |\n",
    "| 🧠 **State**                 | A Python dict-like object holding all variables — conversation history, user input, flags, etc. |\n",
    "| 🔁 **Edges**                 | Transitions between nodes based on logic or conditions from the state.                          |\n",
    "| 🔗 **Nodes**                 | Functional units — each node does something (e.g., call LLM, query DB, save memory).            |\n",
    "| 🧩 **Memory**                | Integrated via LangChain memory modules – stores and recalls state (chat history, facts, etc.). |\n",
    "| 👨‍👩‍👧‍👦 **Multi-Actors** | Different agents/humans acting on state. Each actor is a decision-maker.                        |\n",
    "| 🧑‍💼 **Human-in-the-loop**  | A node where a human can edit or approve the output. Pauses execution and resumes on input.     |\n",
    "| 🔄 **Conditional Routing**   | Logic-based routing using state (e.g., “if confidence < 0.7, ask a human”).                     |\n",
    "| 📄 **Persistence**           | Optional: state can be stored (e.g., to a DB) for resume/analysis.                              |\n",
    "\n",
    "---\n",
    "\n",
    "## 👶 **8. How LangGraph Works (Explained to a 5-Year-Old with Visuals)**\n",
    "\n",
    "### 🧸 Analogy:\n",
    "\n",
    "Imagine you're playing a **board game**.\n",
    "\n",
    "* Each **square** is a **task** you have to do (ask LLM, talk to human).\n",
    "* You carry a **backpack** (state) that holds everything you've learned.\n",
    "* Depending on what's in your backpack, you move to a different square (routing).\n",
    "* Some squares are for **you** (LLM), some are for your **friends** (other agents), and some for **mom/dad** (human-in-the-loop).\n",
    "* At the end, you’ve used everything you know and what others helped you with to finish the game.\n",
    "\n",
    "### 🖼️ Visualized Diagram (Described):\n",
    "\n",
    "```\n",
    "   +------------+      yes     +-------------+\n",
    "   |  Start     | ------------> | Ask LLM 1  |\n",
    "   +------------+              +-------------+\n",
    "         |                          |\n",
    "         | no                       v\n",
    "         v                  +--------------+\n",
    "   +-------------+          |  Add to      |\n",
    "   | Check State |--------->|  Memory      |\n",
    "   +-------------+          +--------------+\n",
    "         |\n",
    "         v\n",
    "   +-----------------+\n",
    "   | Ask a Human     |\n",
    "   +-----------------+\n",
    "         |\n",
    "         v\n",
    "   +--------------+\n",
    "   |  Final Answer|\n",
    "   +--------------+\n",
    "```\n",
    "\n",
    "* Each box is a **node**.\n",
    "* Arrows are **decisions** or **state-based transitions**.\n",
    "* The **memory** carries the **backpack** throughout the journey.\n",
    "\n",
    "---\n",
    "\n",
    "## 🧠 Important Practice Questions (Must-Know)\n",
    "\n",
    "These will help you **solidify** your understanding:\n",
    "\n",
    "1. **What is a LangGraph and how is it different from LangChain chains?**\n",
    "2. **What makes LangGraph stateful, and why is that important?**\n",
    "3. **How would you model a multi-step customer service agent using LangGraph?**\n",
    "4. **What are the benefits of using graphs instead of linear chains in LLM applications?**\n",
    "5. **Explain how LangGraph enables human-in-the-loop and why it's valuable.**\n",
    "6. **Compare Pregel and LangGraph in the context of message-passing and state updates.**\n",
    "7. **What role does memory play in LangGraph, and how is it implemented?**\n",
    "8. **What challenges does LangGraph solve that LLM toolkits previously didn’t?**\n",
    "9. **Can LangGraph run asynchronously or in parallel? How would that work?**\n",
    "10. **What are the best practices for error handling and state persistence in LangGraph applications?**\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b79240f",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### **1. What is a LangGraph and how is it different from LangChain chains?**\n",
    "\n",
    "| Aspect              | **LangGraph**                                 | **LangChain Chain**                  |\n",
    "| ------------------- | --------------------------------------------- | ------------------------------------ |\n",
    "| 🧠 **Statefulness** | Stateful (remembers & updates a shared state) | Typically stateless or semi-stateful |\n",
    "| 🔁 **Flow Type**    | Graph (can loop, branch, have conditionals)   | Linear sequence of steps             |\n",
    "| 🧩 **Structure**    | Nodes + Edges (graph of logic)                | Step-by-step chain                   |\n",
    "| 👥 **Multi-actor**  | Supports multiple agents/humans in one graph  | Usually single-agent focus           |\n",
    "| 🎯 **Use Case Fit** | Complex, multi-step, dynamic flows            | Simple, fixed LLM tasks              |\n",
    "\n",
    "> 💡 **LangGraph** is for **dynamic, decision-based logic**, while **LangChain Chains** are for **predictable sequences**.\n",
    "\n",
    "---\n",
    "\n",
    "### **2. What makes LangGraph stateful, and why is that important?**\n",
    "\n",
    "* In LangGraph, each node **reads and updates a shared state object** (typically a Python dictionary).\n",
    "* This **state object travels** across all nodes and accumulates **memory**, **results**, **flags**, and **control decisions**.\n",
    "\n",
    "**Why important?**\n",
    "\n",
    "* LLMs are normally **stateless**, meaning they forget past interactions.\n",
    "* LangGraph allows an app to:\n",
    "\n",
    "  * Track context across steps\n",
    "  * Make decisions (e.g., if confidence < 0.6, retry)\n",
    "  * Support real conversations\n",
    "  * Let multiple agents access and contribute to shared memory\n",
    "\n",
    "✅ It enables **real, evolving applications** — like a chatbot that remembers what you told it yesterday.\n",
    "\n",
    "---\n",
    "\n",
    "### **3. How would you model a multi-step customer service agent using LangGraph?**\n",
    "\n",
    "#### 🧾 Example:\n",
    "\n",
    "```plaintext\n",
    "Customer Input → Route Request →\n",
    "→ If Refund Needed → Ask LLM 1 → Validate Info →\n",
    "→ Ask Human (if refund > $100) →\n",
    "→ Generate Final Reply → Save to CRM\n",
    "```\n",
    "\n",
    "#### ✅ Nodes:\n",
    "\n",
    "* LLM 1: Interprets user request\n",
    "* Validator Node: Checks required fields\n",
    "* Human Node: Escalates if sensitive\n",
    "* Finalizer: Generates reply and logs state\n",
    "\n",
    "#### ✅ State:\n",
    "\n",
    "* `customer_input`\n",
    "* `issue_type`\n",
    "* `validated_info`\n",
    "* `refund_required`\n",
    "* `final_response`\n",
    "\n",
    "LangGraph is ideal here since it:\n",
    "\n",
    "* Tracks conversation over multiple steps\n",
    "* Makes decisions (e.g., refund limit triggers human)\n",
    "* Allows integration with systems like CRM\n",
    "\n",
    "---\n",
    "\n",
    "### **4. What are the benefits of using graphs instead of linear chains in LLM applications?**\n",
    "\n",
    "| Benefit                      | Explanation                                                                    |\n",
    "| ---------------------------- | ------------------------------------------------------------------------------ |\n",
    "| 🔁 **Conditional Logic**     | Graphs allow **if-else branching**, retries, and loops.                        |\n",
    "| 🔄 **Reusable Nodes**        | Nodes can be reused by multiple paths.                                         |\n",
    "| 🔁 **Dynamic Transitions**   | Next step decided by runtime state.                                            |\n",
    "| 👥 **Multi-actor Design**    | Agents or humans can intervene based on context.                               |\n",
    "| 🧠 **State-Aware Execution** | Execution decisions based on current state (e.g., escalate if low confidence). |\n",
    "\n",
    "> 📈 **LangGraph** lets you build **smart and adaptive apps**, not just rigid pipelines.\n",
    "\n",
    "---\n",
    "\n",
    "### **5. Explain how LangGraph enables human-in-the-loop and why it's valuable.**\n",
    "\n",
    "#### ✅ How:\n",
    "\n",
    "* LangGraph supports **human nodes** that:\n",
    "\n",
    "  * Pause execution\n",
    "  * Wait for manual input (e.g., approval, editing)\n",
    "  * Resume the graph flow after input is received\n",
    "\n",
    "#### ✅ Why it's Valuable:\n",
    "\n",
    "| Reason                          | Explanation                                                  |\n",
    "| ------------------------------- | ------------------------------------------------------------ |\n",
    "| 🛑 **Intervene on Errors**      | If an LLM makes a wrong prediction, humans can correct it.   |\n",
    "| 🧑‍⚖️ **Review Critical Steps** | Use in compliance workflows where human review is mandatory. |\n",
    "| 👥 **Collaboration**            | Combine human expertise with LLM automation.                 |\n",
    "| 🔐 **Safety & Control**         | Add control over sensitive actions (e.g., money transfer).   |\n",
    "\n",
    "> Example: In a legal contract review, a human can approve the LLM's summary before sending it to a client.\n",
    "\n",
    "---\n",
    "\n",
    "### **6. Compare Pregel and LangGraph in the context of message-passing and state updates.**\n",
    "\n",
    "| Concept                | **Pregel**                                | **LangGraph**                                       |\n",
    "| ---------------------- | ----------------------------------------- | --------------------------------------------------- |\n",
    "| 🕸️ **Architecture**   | Graph-parallel computing (e.g., PageRank) | Graph of LLM function nodes                         |\n",
    "| 📤 **Message Passing** | Nodes send/receive messages in supersteps | Nodes pass updated **state** to each other          |\n",
    "| 🔁 **State Update**    | Each vertex updates its local state       | Each node reads/writes to a **shared state object** |\n",
    "| ⚙️ **Control Flow**    | Predefined, parallel computation cycles   | Dynamic control flow with conditional transitions   |\n",
    "\n",
    "> LangGraph is **inspired by Pregel** — both use graph flows and evolving state, but LangGraph is applied to LLM and agent logic.\n",
    "\n",
    "---\n",
    "\n",
    "### **7. What role does memory play in LangGraph, and how is it implemented?**\n",
    "\n",
    "**Memory in LangGraph** refers to storing **contextual data** such as:\n",
    "\n",
    "* Conversation history\n",
    "* Facts extracted\n",
    "* Flags or state indicators\n",
    "\n",
    "#### ✅ Implemented via:\n",
    "\n",
    "* LangChain’s `Memory` classes (like `ConversationBufferMemory`)\n",
    "* Custom state fields (`state[\"history\"]`, `state[\"facts\"]`)\n",
    "\n",
    "#### ✅ Used for:\n",
    "\n",
    "* Carrying user context across steps\n",
    "* Making decisions (e.g., remembering that user is VIP)\n",
    "* Ensuring that LLMs don’t forget previous turns\n",
    "\n",
    "> LangGraph turns LLM workflows into **memory-aware agents** that grow smarter over time.\n",
    "\n",
    "---\n",
    "\n",
    "### **8. What challenges does LangGraph solve that LLM toolkits previously didn’t?**\n",
    "\n",
    "| Challenge                             | LangGraph Solution                         |\n",
    "| ------------------------------------- | ------------------------------------------ |\n",
    "| ❌ Stateless interactions              | ✅ Shared state & memory                    |\n",
    "| ❌ Hard to model complex flows         | ✅ Graph-based branching, looping           |\n",
    "| ❌ No real support for multiple agents | ✅ Multi-actor orchestration                |\n",
    "| ❌ Manual human-in-loop integration    | ✅ Built-in pause/wait/resume human support |\n",
    "| ❌ Unstructured logic                  | ✅ Visualizable, modular graph-based logic  |\n",
    "\n",
    "> LangGraph is like a **smart conductor** in an LLM orchestra, directing every part precisely.\n",
    "\n",
    "---\n",
    "\n",
    "### **9. Can LangGraph run asynchronously or in parallel? How would that work?**\n",
    "\n",
    "Yes! LangGraph supports **asynchronous execution** using Python's `async` features.\n",
    "\n",
    "#### ✅ How Parallelism Works:\n",
    "\n",
    "* **Parallel Branching**: You can split the flow and run **two branches in parallel** using custom logic or concurrency in Python.\n",
    "* **Async Nodes**: Each node function can be `async def` and await API calls or long tasks.\n",
    "\n",
    "#### Example Use Case:\n",
    "\n",
    "* You query **two LLM agents simultaneously**:\n",
    "\n",
    "  * One for sentiment\n",
    "  * One for classification\n",
    "* Once both are done, merge the results in state.\n",
    "\n",
    "LangGraph handles concurrency elegantly in workflows that support async Python patterns.\n",
    "\n",
    "---\n",
    "\n",
    "### **10. What are the best practices for error handling and state persistence in LangGraph applications?**\n",
    "\n",
    "#### ✅ Error Handling:\n",
    "\n",
    "* Use **try-except** inside node functions\n",
    "* Log failures to the state (`state[\"error\"]`)\n",
    "* Add fallback nodes if a failure occurs\n",
    "* Use `retry` nodes or circuit breakers\n",
    "\n",
    "#### ✅ State Persistence:\n",
    "\n",
    "* Store state in:\n",
    "\n",
    "  * JSON\n",
    "  * Redis\n",
    "  * SQL/NoSQL DB\n",
    "  * LangChain integrations (e.g., ChromaDB)\n",
    "* Serialize state at checkpoints for:\n",
    "\n",
    "  * Resuming sessions\n",
    "  * Audit logs\n",
    "  * Replay/debug\n",
    "\n",
    "#### ✅ Pro Tips:\n",
    "\n",
    "* Validate input/output of each node\n",
    "* Use a debug flag in state for verbose logs\n",
    "* Limit state size to avoid slow serialization\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ Summary Table of Key Insights\n",
    "\n",
    "| Question                    | Takeaway                                      |\n",
    "| --------------------------- | --------------------------------------------- |\n",
    "| What is LangGraph?          | A graph-based, stateful LLM app engine        |\n",
    "| Stateful vs Stateless       | State helps apps remember and evolve          |\n",
    "| Real-world modeling         | Graph enables rich, branching logic           |\n",
    "| Benefits of graphs          | Flexibility, reuse, and reactivity            |\n",
    "| HITL flows                  | Pause and resume with human input             |\n",
    "| Pregel and Beam inspiration | Graph, state mutation, message-passing        |\n",
    "| Role of memory              | Powers reasoning and continuity               |\n",
    "| Problems solved             | Stateless LLMs, rigid flows, no collaboration |\n",
    "| Async support               | Enables fast, concurrent agent behavior       |\n",
    "| Best practices              | Robust error handling, persist smartly        |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9568948",
   "metadata": {},
   "source": [
    "**More complex LangGraph visualization flow** that models a **multi-agent customer support workflow**. This example includes:\n",
    "\n",
    "* Multiple LLM agents\n",
    "* Conditional branching\n",
    "* Human-in-the-loop (HITL)\n",
    "* Memory usage\n",
    "* State evolution\n",
    "* Error handling\n",
    "\n",
    "---\n",
    "\n",
    "## 🧠 **Use Case**: Multi-Agent Support Bot with Escalation and Logging\n",
    "\n",
    "### 💡 Scenario:\n",
    "\n",
    "A user submits a support query. The system:\n",
    "\n",
    "1. Classifies the issue (billing, tech, general).\n",
    "2. Routes to the correct agent.\n",
    "3. Each agent attempts a resolution.\n",
    "4. If confidence is low or issue is sensitive, it escalates to a human.\n",
    "5. Logs the interaction in CRM.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔄 LangGraph Visual Flow:\n",
    "\n",
    "```plaintext\n",
    "               ┌────────────────────┐\n",
    "               │  Start (Input)     │\n",
    "               └────────┬───────────┘\n",
    "                        │\n",
    "                        ▼\n",
    "             ┌────────────────────────┐\n",
    "             │  LLM: Classify Issue   │\n",
    "             └────────┬───────────────┘\n",
    "                      │\n",
    "        ┌─────────────┼────────────────────────┐\n",
    "        ▼             ▼                        ▼\n",
    "┌────────────┐ ┌──────────────┐       ┌─────────────────┐\n",
    "│ Billing Bot│ │ Tech Support │       │ General Agent   │\n",
    "└─────┬──────┘ └──────┬────────┘       └────────┬────────┘\n",
    "      │               │                         │\n",
    "      ▼               ▼                         ▼\n",
    " ┌──────────────┐ ┌──────────────┐      ┌────────────────┐\n",
    " │Confidence > 0.7│ │Confidence > 0.7│      │Confidence > 0.7 │\n",
    " └────┬──────────┘ └────┬──────────┘      └────┬─────────────┘\n",
    "      │ Yes             │ Yes                   │ Yes\n",
    "      ▼                 ▼                       ▼\n",
    "┌─────────────┐ ┌─────────────┐         ┌────────────────┐\n",
    "│ Final Reply │ │ Final Reply │         │ Final Reply    │\n",
    "└────┬────────┘ └────┬────────┘         └────┬────────────┘\n",
    "     │               │                        │\n",
    "     ▼               ▼                        ▼\n",
    " ┌────────────┐ ┌────────────┐         ┌────────────────┐\n",
    " │   Logger   │ │   Logger   │         │   Logger       │\n",
    " └────┬───────┘ └────┬───────┘         └────┬────────────┘\n",
    "      │               │                        │\n",
    "      ▼               ▼                        ▼\n",
    " ┌────────────┐ ┌────────────┐         ┌────────────────┐\n",
    " │ End State  │ │ End State  │         │ End State      │\n",
    " └────────────┘ └────────────┘         └────────────────┘\n",
    "\n",
    "         ↓↓↓  IF CONFIDENCE < 0.7 ↓↓↓\n",
    "\n",
    "                   ┌──────────────────────┐\n",
    "                   │ Human Escalation    │\n",
    "                   └────────┬─────────────┘\n",
    "                            ▼\n",
    "                   ┌──────────────────────┐\n",
    "                   │ Human Enters Reply  │\n",
    "                   └────────┬─────────────┘\n",
    "                            ▼\n",
    "                   ┌──────────────────────┐\n",
    "                   │ Log & End State     │\n",
    "                   └──────────────────────┘\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 🔍 **What's Happening at Each Step**\n",
    "\n",
    "| **Node**             | **Purpose**                                                                                          |\n",
    "| -------------------- | ---------------------------------------------------------------------------------------------------- |\n",
    "| **Start**            | Receives user query; stored in state `state[\"input\"]`.                                               |\n",
    "| **LLM Classifier**   | Classifies intent into `billing`, `tech`, or `general`. Saves to `state[\"category\"]`.                |\n",
    "| **Routing**          | Based on classification, routes to the appropriate agent node.                                       |\n",
    "| **Agent Nodes**      | Each specialized LLM tries to resolve the issue. Sets `state[\"response\"]` and `state[\"confidence\"]`. |\n",
    "| **Confidence Check** | If `confidence >= 0.7`, the answer is accepted. If not, it's escalated.                              |\n",
    "| **Human Escalation** | Pauses the graph and waits for a human to input or edit response.                                    |\n",
    "| **Logger Node**      | Logs full session (`input`, `response`, `agent used`, `confidence`) to a CRM.                        |\n",
    "| **End Node**         | Graph completes here; state is saved/finalized.                                                      |\n",
    "\n",
    "---\n",
    "\n",
    "### 💾 **State Fields Example**\n",
    "\n",
    "```python\n",
    "state = {\n",
    "  \"input\": \"I was overcharged on my bill\",\n",
    "  \"category\": \"billing\",\n",
    "  \"response\": \"We're sorry. Your overcharge will be refunded.\",\n",
    "  \"confidence\": 0.92,\n",
    "  \"escalated\": False,\n",
    "  \"final_response\": \"We're sorry. Your overcharge will be refunded.\",\n",
    "  \"history\": [...],\n",
    "}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 👥 **Human-In-The-Loop (HITL) Flow**\n",
    "\n",
    "* If any agent's `confidence < 0.7`, graph **pauses**\n",
    "* Human gets a notification (e.g., via UI or Slack)\n",
    "* Human reviews and enters response\n",
    "* Graph resumes and continues to logging\n",
    "\n",
    "---\n",
    "\n",
    "### 🧠 **Memory in the Flow**\n",
    "\n",
    "LangGraph state acts as memory:\n",
    "\n",
    "* Keeps classification info\n",
    "* Tracks which agent was used\n",
    "* Stores user inputs + LLM responses\n",
    "* Can optionally save full chat history using `ConversationBufferMemory`\n",
    "\n",
    "---\n",
    "\n",
    "### 🧪 **What Makes This Graph Powerful?**\n",
    "\n",
    "✅ Dynamic Routing\n",
    "✅ Memory and State Tracking\n",
    "✅ Confidence-Driven Decision Making\n",
    "✅ Human Escalation\n",
    "✅ Structured Logging\n",
    "✅ Modular Nodes = Easily testable and reusable\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d1349b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
