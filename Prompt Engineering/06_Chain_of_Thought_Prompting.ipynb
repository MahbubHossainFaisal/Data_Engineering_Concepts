{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "462b38be",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## üîπ 1. What is Chain of Thought (CoT) Prompting?\n",
    "\n",
    "### ‚úÖ Definition:\n",
    "\n",
    "> **Chain of Thought (CoT)** prompting is a technique where you **explicitly instruct the model to reason step by step** before giving the final answer.\n",
    "\n",
    "Rather than jumping to an answer, the model walks through its logic.\n",
    "\n",
    "---\n",
    "\n",
    "## üîπ 2. Concept of CoT\n",
    "\n",
    "Think of how **humans solve problems**:\n",
    "\n",
    "* We break them down into smaller pieces\n",
    "* We follow logical steps\n",
    "* Only then do we reach a decision\n",
    "\n",
    "LLMs can do the same ‚Äî **if prompted correctly**.\n",
    "\n",
    "### üß† Key CoT Pattern:\n",
    "\n",
    "> \"Let's think step-by-step.\"\n",
    "\n",
    "---\n",
    "\n",
    "## üîπ 3. What Problem Does CoT Solve?\n",
    "\n",
    "| Without CoT                          | With CoT                                       |\n",
    "| ------------------------------------ | ---------------------------------------------- |\n",
    "| ‚ùå Jumps to conclusion                | ‚úÖ Walks through logic                          |\n",
    "| ‚ùå May hallucinate                    | ‚úÖ More factual consistency                     |\n",
    "| ‚ùå Struggles with multi-part problems | ‚úÖ Breaks them down                             |\n",
    "| ‚ùå Bad at reasoning                   | ‚úÖ Significantly improved reasoning performance |\n",
    "\n",
    "---\n",
    "\n",
    "## üîπ 4. ‚ú® Real Case Scenario\n",
    "\n",
    "### üéØ Task: Calculate how many apples Sarah has left.\n",
    "\n",
    "#### üßæ Input:\n",
    "\n",
    "> Sarah had 15 apples. She gave 3 to Tom and 4 to Lily. Then she bought 2 more. How many apples does she have now?\n",
    "\n",
    "---\n",
    "\n",
    "### ‚ùå Generic Prompt (No CoT):\n",
    "\n",
    "```txt\n",
    "How many apples does Sarah have now? Sarah had 15, gave away 3 and 4, then bought 2 more.\n",
    "```\n",
    "\n",
    "#### Output:\n",
    "\n",
    "```txt\n",
    "Sarah has 10 apples.\n",
    "```\n",
    "\n",
    "üòê Seems fine‚Ä¶ but it's fragile. In harder questions, this will **often fail**.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ CoT Prompt (Best Practice Applied):\n",
    "\n",
    "```txt\n",
    "Sarah had 15 apples.\n",
    "She gave 3 to Tom ‚Üí 15 - 3 = 12\n",
    "She gave 4 to Lily ‚Üí 12 - 4 = 8\n",
    "She bought 2 more ‚Üí 8 + 2 = 10\n",
    "So, Sarah has 10 apples now.\n",
    "```\n",
    "\n",
    "### ‚úÖ CoT Prompt Template:\n",
    "\n",
    "```txt\n",
    "Let‚Äôs think step-by-step.\n",
    "Sarah had 15 apples.\n",
    "She gave away 3 ‚Üí 15 - 3 = 12\n",
    "Then gave 4 more ‚Üí 12 - 4 = 8\n",
    "Then bought 2 ‚Üí 8 + 2 = 10\n",
    "Answer: 10 apples\n",
    "```\n",
    "\n",
    "Much **more structured**, easy to **audit**, and can **scale** to complex logic.\n",
    "\n",
    "---\n",
    "\n",
    "## üîó CoT + Few-Shot Prompting = üî•üî•üî•\n",
    "\n",
    "LLMs often **learn better by example**.\n",
    "\n",
    "Let‚Äôs add **few-shot examples** **+ CoT logic** to solve a harder reasoning task.\n",
    "\n",
    "---\n",
    "\n",
    "### üéØ Goal: Solve math word problems (with CoT + few-shot)\n",
    "\n",
    "```txt\n",
    "You are a math tutor. Solve each problem by reasoning step-by-step and then output only the final answer.\n",
    "\n",
    "Example 1:\n",
    "Question: A train travels at 60 km/h for 2 hours and then 80 km/h for 1 hour. What is the total distance?\n",
    "Step-by-step:\n",
    "1. First leg: 60 √ó 2 = 120 km\n",
    "2. Second leg: 80 √ó 1 = 80 km\n",
    "3. Total = 120 + 80 = 200 km\n",
    "Answer: 200 km\n",
    "\n",
    "Example 2:\n",
    "Question: A shop sells pencils at $2 each. If you buy 4 pencils and pay with a $10 bill, how much change do you get?\n",
    "Step-by-step:\n",
    "1. Total cost = 4 √ó 2 = 8\n",
    "2. Change = 10 - 8 = 2\n",
    "Answer: 2 dollars\n",
    "\n",
    "Now solve:\n",
    "Question: Sarah had 15 apples. She gave 3 to Tom and 4 to Lily. Then she bought 2 more. How many apples does she have now?\n",
    "```\n",
    "\n",
    "‚úÖ This gives **superb reasoning** + solid pattern-following.\n",
    "\n",
    "---\n",
    "\n",
    "## üéì Best Practices for Chain of Thought\n",
    "\n",
    "| Practice                             | Description                     |\n",
    "| ------------------------------------ | ------------------------------- |\n",
    "| üß† Add ‚ÄúLet‚Äôs think step-by-step‚Äù    | Triggers reasoning mode         |\n",
    "| üîÅ Use multiple examples             | LLMs mimic logic patterns       |\n",
    "| üß© Break into substeps               | Smaller chunks = more accuracy  |\n",
    "| üß™ Prefer structured format          | Numbered steps or bullet points |\n",
    "| üì§ Encourage final answer separately | ‚ÄúAnswer: \\_\\_\\_‚Äù style          |\n",
    "\n",
    "---\n",
    "\n",
    "## üîç Advanced: Self-Consistency Decoding (used in APIs)\n",
    "\n",
    "> In CoT, **\"Self-consistency\"** is a decoding strategy where multiple reasoning paths are sampled and **the most consistent answer is picked**.\n",
    "\n",
    "### How it works:\n",
    "\n",
    "* Run CoT prompt **multiple times**\n",
    "* Gather all answers\n",
    "* Select the **most frequent** answer (majority vote)\n",
    "\n",
    "‚úÖ Helps improve **stability**\n",
    "‚úÖ Reduces chance of following incorrect reasoning\n",
    "‚úÖ Often used in **production-grade tools** like Google‚Äôs PaLM, or in **research-level LLMs**\n",
    "\n",
    "---\n",
    "\n",
    "## üß† Summary of CoT Value\n",
    "\n",
    "| Feature              | Why It's Useful                                  |\n",
    "| -------------------- | ------------------------------------------------ |\n",
    "| Step-by-step logic   | Mimics human reasoning                           |\n",
    "| Works with few-shot  | Improves complex task performance                |\n",
    "| Auditable            | Easy to check reasoning chain                    |\n",
    "| Flexible             | Use in math, logic, science, even business cases |\n",
    "| Self-consistent mode | Boosts quality at scale                          |\n",
    "\n",
    "---\n",
    "\n",
    "## üì¶ When to Use CoT Prompting\n",
    "\n",
    "‚úÖ Great for:\n",
    "\n",
    "* Math word problems\n",
    "* Logic puzzles\n",
    "* Decision-making\n",
    "* Classification with rules\n",
    "* Any multi-step task\n",
    "\n",
    "‚ùå Not always needed for:\n",
    "\n",
    "* Simple factual lookup\n",
    "* One-line tasks\n",
    "* Creative writing\n",
    "\n",
    "---\n",
    "\n",
    "## üöÄ Ready-to-Use CoT Template\n",
    "\n",
    "```txt\n",
    "You are a smart assistant that solves reasoning problems step-by-step.\n",
    "\n",
    "Task: [Insert your task]\n",
    "\n",
    "Let‚Äôs think step-by-step.\n",
    "[Leave this line to trigger CoT mode]\n",
    "```\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ff3239",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
