{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766997d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as func\n",
    "\n",
    "spark = SparkSession.builder.appName(\"WordCount\").getOrCreate()\n",
    "\n",
    "\n",
    "inputDF = spark.read.text(\"file:///C:/Users/Mahbub/Desktop/Data Engineering/Spark/book.txt\")\n",
    "\n",
    "\n",
    "words = inputDF.select(func.explode(func.split(inputDF.value,\"\\\\W+\")).alias(\"word\"))\n",
    "\n",
    "wordsWithoutEmptyString = words.filter(words.word != \"\")\n",
    "\n",
    "smallerCaseWords =  words.select(func.lower(wordsWithoutEmptyString.word).alias(\"word\"))\n",
    "\n",
    "wordCount = smallerCaseWords.groupBy(\"word\").count()\n",
    "\n",
    "wordCountSorted = wordCount.sort(\"count\")\n",
    "\n",
    "wordCountSorted.show(wordCountSorted.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26317f9",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### Code Explanation\n",
    "\n",
    "#### **1. Importing Required Libraries**\n",
    "```python\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as func\n",
    "```\n",
    "- `SparkSession`: Entry point for PySpark applications.\n",
    "- `functions` (aliased as `func`): Provides utility functions like `explode`, `split`, `lower`, etc.\n",
    "\n",
    "---\n",
    "\n",
    "#### **2. Initializing SparkSession**\n",
    "```python\n",
    "spark = SparkSession.builder.appName(\"WordCount\").getOrCreate()\n",
    "```\n",
    "- Creates a `SparkSession` named \"WordCount\".\n",
    "- This is required to work with DataFrames in PySpark.\n",
    "\n",
    "---\n",
    "\n",
    "#### **3. Reading the Input File**\n",
    "```python\n",
    "inputDF = spark.read.text(\"file:///C:/Users/Mahbub/Desktop/Data Engineering/Spark/book.txt\")\n",
    "```\n",
    "- Reads the text file into a DataFrame named `inputDF`.\n",
    "- Each line of the file becomes a row in the DataFrame under the column `value`.\n",
    "\n",
    "**Sample Input File (`book.txt`):**\n",
    "```\n",
    "Hello world\n",
    "This is a test\n",
    "Hello Spark\n",
    "```\n",
    "\n",
    "**`inputDF`:**\n",
    "\n",
    "| value           |\n",
    "|------------------|\n",
    "| Hello world      |\n",
    "| This is a test   |\n",
    "| Hello Spark      |\n",
    "\n",
    "---\n",
    "\n",
    "#### **4. Splitting Lines into Words**\n",
    "```python\n",
    "words = inputDF.select(func.explode(func.split(inputDF.value, \"\\\\W+\")).alias(\"word\"))\n",
    "```\n",
    "- **`split(inputDF.value, \"\\\\W+\")`:**\n",
    "  - Splits each line into words based on non-word characters (`\\W+`).\n",
    "  - Example: `\"Hello world\"` → `[\"Hello\", \"world\"]`.\n",
    "\n",
    "- **`explode`:**\n",
    "  - Expands each array element into a separate row.\n",
    "  - Example: `[\"Hello\", \"world\"]` → Two rows: `Hello`, `world`.\n",
    "\n",
    "**`words`:**\n",
    "\n",
    "| word            |\n",
    "|------------------|\n",
    "| Hello           |\n",
    "| world           |\n",
    "| This            |\n",
    "| is              |\n",
    "| a               |\n",
    "| test            |\n",
    "| Hello           |\n",
    "| Spark           |\n",
    "\n",
    "---\n",
    "\n",
    "#### **5. Filtering Out Empty Strings**\n",
    "```python\n",
    "wordsWithoutEmptyString = words.filter(words.word != \"\")\n",
    "```\n",
    "- Removes rows where the word is an empty string (`\"\"`).\n",
    "\n",
    "---\n",
    "\n",
    "#### **6. Converting Words to Lowercase**\n",
    "```python\n",
    "smallerCaseWords = words.select(func.lower(wordsWithoutEmptyString.word).alias(\"word\"))\n",
    "```\n",
    "- Converts all words to lowercase using `lower`.\n",
    "\n",
    "**`smallerCaseWords`:**\n",
    "\n",
    "| word            |\n",
    "|------------------|\n",
    "| hello           |\n",
    "| world           |\n",
    "| this            |\n",
    "| is              |\n",
    "| a               |\n",
    "| test            |\n",
    "| hello           |\n",
    "| spark           |\n",
    "\n",
    "---\n",
    "\n",
    "#### **7. Counting Word Occurrences**\n",
    "```python\n",
    "wordCount = smallerCaseWords.groupBy(\"word\").count()\n",
    "```\n",
    "- Groups the words and counts their occurrences.\n",
    "\n",
    "**`wordCount`:**\n",
    "\n",
    "| word   | count |\n",
    "|--------|-------|\n",
    "| hello  | 2     |\n",
    "| world  | 1     |\n",
    "| this   | 1     |\n",
    "| is     | 1     |\n",
    "| a      | 1     |\n",
    "| test   | 1     |\n",
    "| spark  | 1     |\n",
    "\n",
    "---\n",
    "\n",
    "#### **8. Sorting Words by Count**\n",
    "```python\n",
    "wordCountSorted = wordCount.sort(\"count\")\n",
    "```\n",
    "- Sorts the DataFrame by the `count` column in ascending order.\n",
    "\n",
    "**`wordCountSorted`:**\n",
    "\n",
    "| word   | count |\n",
    "|--------|-------|\n",
    "| world  | 1     |\n",
    "| this   | 1     |\n",
    "| is     | 1     |\n",
    "| a      | 1     |\n",
    "| test   | 1     |\n",
    "| spark  | 1     |\n",
    "| hello  | 2     |\n",
    "\n",
    "---\n",
    "\n",
    "#### **9. Displaying Results**\n",
    "```python\n",
    "wordCountSorted.show(wordCountSorted.count())\n",
    "```\n",
    "- Displays all rows of the sorted word count DataFrame.\n",
    "\n",
    "**Output:**\n",
    "```\n",
    "\n",
    "+-----+-----+\n",
    "| word|count|\n",
    "+-----+-----+\n",
    "|world|    1|\n",
    "|this |    1|\n",
    "|is   |    1|\n",
    "|a    |    1|\n",
    "|test |    1|\n",
    "|spark|    1|\n",
    "|hello|    2|\n",
    "+-----+-----+\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Key Concepts Illustrated\n",
    "1. **DataFrame Operations**: Reading, transforming, and analyzing text data.\n",
    "2. **Functions**: Using `split`, `explode`, `lower`, `groupBy`, and `count` for text processing.\n",
    "3. **Chaining Transformations**: How multiple transformations are applied in sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e3e9c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
