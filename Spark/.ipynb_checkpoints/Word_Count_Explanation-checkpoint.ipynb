{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc60d2f3",
   "metadata": {},
   "source": [
    "### Code:\n",
    "```python\n",
    "from pyspark import SparkConf, SparkContext\n",
    "import re\n",
    "\n",
    "# Configure Spark\n",
    "conf = SparkConf().setMaster(\"local\").setAppName(\"WordCount\")\n",
    "sc = SparkContext(conf=conf)\n",
    "\n",
    "# Function to normalize words\n",
    "def normalize_words(line):\n",
    "    # Split line into words using regex for non-word characters\n",
    "    return re.compile(r'\\W+', re.UNICODE).split(line.lower())\n",
    "\n",
    "# Load the text file\n",
    "lines = sc.textFile(\"file:///spark/weather1800.csv\")\n",
    "\n",
    "# Normalize words\n",
    "words = lines.flatMap(normalize_words)\n",
    "\n",
    "# Count occurrences of each word\n",
    "word_counts = words.map(lambda word: (word, 1)).reduceByKey(lambda x, y: x + y)\n",
    "\n",
    "# Sort by counts (ascending order)\n",
    "word_counts_sorted = word_counts.map(lambda pair: (pair[1], pair[0])).sortByKey()\n",
    "\n",
    "# Collect results\n",
    "results = word_counts_sorted.collect()\n",
    "\n",
    "# Print results\n",
    "for count, word in results:\n",
    "    if word:  # Exclude empty words\n",
    "        print(f\"{word}:\\t{count}\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Explanation of the Code:\n",
    "1. **Setup**:\n",
    "   - `SparkConf` and `SparkContext` are configured to create a local Spark application named \"WordCount\".\n",
    "\n",
    "2. **Normalization**:\n",
    "   - The `normalize_words` function converts each line of text to lowercase and splits it into words using a regular expression that matches non-word characters (`\\W+`).\n",
    "\n",
    "3. **Load Data**:\n",
    "   - The `sc.textFile` method reads the input file `weather1800.csv` from the specified path.\n",
    "\n",
    "4. **Transformations**:\n",
    "   - **`flatMap(normalize_words)`**: Splits each line into words and flattens the results into a single RDD.\n",
    "   - **`map(lambda word: (word, 1))`**: Maps each word to a key-value pair `(word, 1)`.\n",
    "   - **`reduceByKey(lambda x, y: x + y)`**: Aggregates the counts for each word by summing the values.\n",
    "\n",
    "5. **Sorting**:\n",
    "   - **`map(lambda pair: (pair[1], pair[0]))`**: Swaps the key-value pairs to `(count, word)` for sorting.\n",
    "   - **`sortByKey()`**: Sorts the RDD by the key (word count) in ascending order.\n",
    "\n",
    "6. **Action**:\n",
    "   - **`collect()`**: Collects the sorted results into a list for further processing.\n",
    "   - **Print Loop**: Iterates over the results and prints the word and its count.\n",
    "\n",
    "---\n",
    "\n",
    "### Sample Input:\n",
    "**Input File (`weather1800.csv`):**\n",
    "```\n",
    "Rainy day in the park\n",
    "Sunny day in the park\n",
    "Rainy day in the city\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Sample Output:\n",
    "```\n",
    "city:   1\n",
    "sunny:  1\n",
    "park:   2\n",
    "rainy:  2\n",
    "in:     3\n",
    "day:    3\n",
    "the:    3\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ab548a",
   "metadata": {},
   "source": [
    "### Using this context here, the difference between map and flatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff895a5",
   "metadata": {},
   "source": [
    "No, `map` cannot perform the same function as `flatMap` in this context because they have distinct purposes in Spark. Here's a detailed explanation of the difference between `map` and `flatMap`:\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Differences Between `map` and `flatMap`**\n",
    "\n",
    "| Feature              | `map`                                                                                     | `flatMap`                                                                                 |\n",
    "|----------------------|------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------|\n",
    "| **Output**           | Transforms each input element into exactly one output element.                           | Transforms each input element into zero, one, or more output elements.                   |\n",
    "| **Structure**        | Maintains a one-to-one mapping (input to output).                                         | Performs a one-to-many mapping (input to multiple outputs) and flattens the results.     |\n",
    "| **Use Case**         | Used when the transformation of input produces exactly one output for each input element. | Used when the transformation produces a list (or iterable) and the output needs flattening. |\n",
    "| **Resulting RDD**    | The resulting RDD has the same number of elements as the input RDD.                       | The resulting RDD may have more, fewer, or the same number of elements as the input RDD. |\n",
    "\n",
    "---\n",
    "\n",
    "### **Why `flatMap` is Needed in the Provided Code**\n",
    "\n",
    "- The `normalize_words` function splits each line into a **list of words**.\n",
    "- If we use `map`, the output of the transformation would be an RDD of lists (nested structure).\n",
    "- Using `flatMap` ensures that the RDD is \"flattened\" so that each word becomes an individual element in the resulting RDD.\n",
    "\n",
    "---\n",
    "\n",
    "### **Example to Illustrate the Difference**\n",
    "\n",
    "#### Input Data:\n",
    "```\n",
    "[\"Rainy day in the park\", \"Sunny day in the park\"]\n",
    "```\n",
    "\n",
    "#### Using `map`:\n",
    "```python\n",
    "lines.map(normalize_words).collect()\n",
    "```\n",
    "**Output:**\n",
    "```python\n",
    "[\n",
    "    ['rainy', 'day', 'in', 'the', 'park'], \n",
    "    ['sunny', 'day', 'in', 'the', 'park']\n",
    "]\n",
    "```\n",
    "- The result is an RDD of lists, which is not suitable for word counting.\n",
    "\n",
    "#### Using `flatMap`:\n",
    "```python\n",
    "lines.flatMap(normalize_words).collect()\n",
    "```\n",
    "**Output:**\n",
    "```python\n",
    "['rainy', 'day', 'in', 'the', 'park', 'sunny', 'day', 'in', 'the', 'park']\n",
    "```\n",
    "- The result is a flat RDD where each word is an individual element, ideal for further transformations like counting.\n",
    "\n",
    "---\n",
    "\n",
    "### **Conclusion**\n",
    "\n",
    "- Use `map` when each input produces exactly one output.\n",
    "- Use `flatMap` when each input can produce multiple outputs and the results need to be flattened into a single RDD.\n",
    "\n",
    "In your code, `flatMap` is essential because the `normalize_words` function returns a list of words, and we need a flat structure for word counting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c0c7d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
