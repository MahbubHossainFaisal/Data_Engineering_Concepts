{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c24eb295",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "# **30 Data Transformation Examples (Stage → Table)**\n",
    "\n",
    "We assume:\n",
    "\n",
    "* Stage: `@mystage` (internal or external)\n",
    "* File formats: CSV/JSON (custom defined)\n",
    "* Target tables exist (`customer_clean`, `sales_clean`, etc.)\n",
    "\n",
    "---\n",
    "\n",
    "## **1. Trim Spaces**\n",
    "\n",
    "```sql\n",
    "INSERT INTO customer_clean (customer_id, customer_name)\n",
    "SELECT \n",
    "    $1::INT,\n",
    "    TRIM($2)\n",
    "FROM @mystage/customers.csv\n",
    "(FILE_FORMAT => my_csv_format);\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Convert to Upper/Lower Case**\n",
    "\n",
    "```sql\n",
    "INSERT INTO customer_clean (customer_id, email)\n",
    "SELECT \n",
    "    $1::INT,\n",
    "    LOWER($2)\n",
    "FROM @mystage/customers.csv\n",
    "(FILE_FORMAT => my_csv_format);\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Substring Extraction**\n",
    "\n",
    "```sql\n",
    "INSERT INTO orders_clean (short_order_id, order_id)\n",
    "SELECT \n",
    "    SUBSTR($1, 1, 5),\n",
    "    $1::INT\n",
    "FROM @mystage/orders.csv\n",
    "(FILE_FORMAT => my_csv_format);\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Replace Special Characters**\n",
    "\n",
    "```sql\n",
    "INSERT INTO customer_clean (customer_id, phone)\n",
    "SELECT \n",
    "    $1::INT,\n",
    "    REGEXP_REPLACE($2, '[^0-9]', '')\n",
    "FROM @mystage/customers.csv\n",
    "(FILE_FORMAT => my_csv_format);\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **5. Concatenate Columns**\n",
    "\n",
    "```sql\n",
    "INSERT INTO customer_clean (customer_id, full_name)\n",
    "SELECT \n",
    "    $1::INT,\n",
    "    CONCAT($2, ' ', $3)\n",
    "FROM @mystage/customers.csv\n",
    "(FILE_FORMAT => my_csv_format);\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **6. Rounding Numbers**\n",
    "\n",
    "```sql\n",
    "INSERT INTO sales_clean (order_id, amount)\n",
    "SELECT \n",
    "    $1::INT,\n",
    "    ROUND($2::NUMBER, 2)\n",
    "FROM @mystage/sales.csv\n",
    "(FILE_FORMAT => my_csv_format);\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **7. Convert String → Number**\n",
    "\n",
    "```sql\n",
    "INSERT INTO sales_clean (order_id, amount)\n",
    "SELECT \n",
    "    $1::INT,\n",
    "    TRY_TO_NUMBER($2) AS amount\n",
    "FROM @mystage/sales.csv\n",
    "(FILE_FORMAT => my_csv_format);\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **8. Handling Nulls with Default Values**\n",
    "\n",
    "```sql\n",
    "INSERT INTO sales_clean (order_id, discount)\n",
    "SELECT \n",
    "    $1::INT,\n",
    "    COALESCE($2::NUMBER, 0)\n",
    "FROM @mystage/sales.csv\n",
    "(FILE_FORMAT => my_csv_format);\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **9. Capping Values**\n",
    "\n",
    "```sql\n",
    "INSERT INTO sales_clean (order_id, amount)\n",
    "SELECT \n",
    "    $1::INT,\n",
    "    LEAST($2::NUMBER, 10000)\n",
    "FROM @mystage/sales.csv\n",
    "(FILE_FORMAT => my_csv_format);\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **10. Categorizing Numeric Ranges**\n",
    "\n",
    "```sql\n",
    "INSERT INTO sales_clean (order_id, amount_category)\n",
    "SELECT \n",
    "    $1::INT,\n",
    "    CASE \n",
    "        WHEN $2::NUMBER < 100 THEN 'SMALL'\n",
    "        WHEN $2::NUMBER BETWEEN 100 AND 1000 THEN 'MEDIUM'\n",
    "        ELSE 'LARGE'\n",
    "    END\n",
    "FROM @mystage/sales.csv\n",
    "(FILE_FORMAT => my_csv_format);\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **11. Convert String to Date**\n",
    "\n",
    "```sql\n",
    "INSERT INTO sales_clean (order_id, order_date)\n",
    "SELECT \n",
    "    $1::INT,\n",
    "    TO_DATE($2, 'YYYY-MM-DD')\n",
    "FROM @mystage/sales.csv\n",
    "(FILE_FORMAT => my_csv_format);\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **12. Extract Year, Month, Day**\n",
    "\n",
    "```sql\n",
    "INSERT INTO sales_clean (order_id, year, month, day)\n",
    "SELECT \n",
    "    $1::INT,\n",
    "    YEAR(TO_DATE($2, 'YYYY-MM-DD')),\n",
    "    MONTH(TO_DATE($2, 'YYYY-MM-DD')),\n",
    "    DAY(TO_DATE($2, 'YYYY-MM-DD'))\n",
    "FROM @mystage/sales.csv\n",
    "(FILE_FORMAT => my_csv_format);\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **13. Date Difference Calculation**\n",
    "\n",
    "```sql\n",
    "INSERT INTO sales_clean (order_id, days_to_ship)\n",
    "SELECT \n",
    "    $1::INT,\n",
    "    DATEDIFF(DAY, TO_DATE($2, 'YYYY-MM-DD'), TO_DATE($3, 'YYYY-MM-DD'))\n",
    "FROM @mystage/sales.csv\n",
    "(FILE_FORMAT => my_csv_format);\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **14. Add/Subtract Days**\n",
    "\n",
    "```sql\n",
    "INSERT INTO sales_clean (order_id, expected_delivery)\n",
    "SELECT \n",
    "    $1::INT,\n",
    "    DATEADD(DAY, 7, TO_DATE($2, 'YYYY-MM-DD'))\n",
    "FROM @mystage/sales.csv\n",
    "(FILE_FORMAT => my_csv_format);\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **15. Truncate to First of Month**\n",
    "\n",
    "```sql\n",
    "INSERT INTO sales_clean (order_id, month_start)\n",
    "SELECT \n",
    "    $1::INT,\n",
    "    DATE_TRUNC('MONTH', TO_DATE($2, 'YYYY-MM-DD'))\n",
    "FROM @mystage/sales.csv\n",
    "(FILE_FORMAT => my_csv_format);\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **16. Standardize Country Codes**\n",
    "\n",
    "```sql\n",
    "INSERT INTO customer_clean (customer_id, country)\n",
    "SELECT \n",
    "    $1::INT,\n",
    "    IFF($2 IN ('USA','US','United States'), 'US', $2)\n",
    "FROM @mystage/customers.csv\n",
    "(FILE_FORMAT => my_csv_format);\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **17. Remove Duplicates (ROW\\_NUMBER)**\n",
    "\n",
    "```sql\n",
    "INSERT INTO customer_deduped\n",
    "SELECT customer_id, name, email\n",
    "FROM (\n",
    "    SELECT \n",
    "        $1::INT AS customer_id,\n",
    "        $2 AS name,\n",
    "        $3 AS email,\n",
    "        ROW_NUMBER() OVER(PARTITION BY $1 ORDER BY $4 DESC) AS rn\n",
    "    FROM @mystage/customers.csv\n",
    "    (FILE_FORMAT => my_csv_format)\n",
    ")\n",
    "WHERE rn = 1;\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **18. Filter Invalid Records**\n",
    "\n",
    "```sql\n",
    "INSERT INTO sales_clean\n",
    "SELECT $1::INT, $2::NUMBER\n",
    "FROM @mystage/sales.csv\n",
    "(FILE_FORMAT => my_csv_format)\n",
    "WHERE $2::NUMBER > 0;\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **19. Conditional Null Handling**\n",
    "\n",
    "```sql\n",
    "INSERT INTO customer_clean (customer_id, phone)\n",
    "SELECT \n",
    "    $1::INT,\n",
    "    NULLIF($2, '')\n",
    "FROM @mystage/customers.csv\n",
    "(FILE_FORMAT => my_csv_format);\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **20. Flag Bad Records**\n",
    "\n",
    "```sql\n",
    "INSERT INTO customer_bad\n",
    "SELECT \n",
    "    $1::INT, \n",
    "    IFF($2 = '' OR $3 = '', 'INVALID', 'VALID') AS record_status\n",
    "FROM @mystage/customers.csv\n",
    "(FILE_FORMAT => my_csv_format);\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **21. Join with Dimension Table**\n",
    "\n",
    "```sql\n",
    "INSERT INTO sales_enriched (order_id, customer_key, amount)\n",
    "SELECT \n",
    "    s.$1::INT AS order_id,\n",
    "    c.customer_key,\n",
    "    s.$2::NUMBER AS amount\n",
    "FROM @mystage/sales.csv s\n",
    "JOIN dim_customers c ON s.$3 = c.customer_id;\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **22. Surrogate Key Generation**\n",
    "\n",
    "```sql\n",
    "INSERT INTO customer_dim (surrogate_key, customer_id)\n",
    "SELECT \n",
    "    MD5($1 || $2) AS surrogate_key,\n",
    "    $1::INT AS customer_id\n",
    "FROM @mystage/customers.csv\n",
    "(FILE_FORMAT => my_csv_format);\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **23. Map Codes to Descriptions**\n",
    "\n",
    "```sql\n",
    "INSERT INTO sales_clean (order_id, status, status_desc)\n",
    "SELECT \n",
    "    $1::INT,\n",
    "    $2 AS status,\n",
    "    DECODE($2, 'P', 'Pending', 'C', 'Completed', 'F', 'Failed') AS status_desc\n",
    "FROM @mystage/sales.csv\n",
    "(FILE_FORMAT => my_csv_format);\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **24. Slowly Changing Dimension (Type 2)**\n",
    "\n",
    "```sql\n",
    "MERGE INTO dim_customers t\n",
    "USING (\n",
    "    SELECT $1::INT AS customer_id, $2 AS email\n",
    "    FROM @mystage/customers.csv\n",
    "    (FILE_FORMAT => my_csv_format)\n",
    ") s\n",
    "ON t.customer_id = s.customer_id\n",
    "WHEN MATCHED AND t.email <> s.email THEN\n",
    "    UPDATE SET t.is_active = FALSE, t.end_date = CURRENT_DATE\n",
    "WHEN NOT MATCHED THEN\n",
    "    INSERT (customer_id, email, start_date, is_active)\n",
    "    VALUES (s.customer_id, s.email, CURRENT_DATE, TRUE);\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **25. Check Referential Integrity**\n",
    "\n",
    "```sql\n",
    "SELECT s.$1::INT AS order_id\n",
    "FROM @mystage/orders.csv s\n",
    "LEFT JOIN dim_customers c ON s.$2 = c.customer_id\n",
    "WHERE c.customer_id IS NULL;\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **26. Extract from JSON**\n",
    "\n",
    "```sql\n",
    "INSERT INTO orders_flat (order_id, customer, total)\n",
    "SELECT \n",
    "    data:order_id::INT,\n",
    "    data:customer::STRING,\n",
    "    data:total::NUMBER\n",
    "FROM @mystage/orders.json\n",
    "(FILE_FORMAT => my_json_format);\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **27. Flatten Nested JSON Arrays**\n",
    "\n",
    "```sql\n",
    "INSERT INTO orders_items (order_id, item_id)\n",
    "SELECT \n",
    "    data:order_id::INT,\n",
    "    item.value:item_id::STRING\n",
    "FROM @mystage/orders.json,\n",
    "LATERAL FLATTEN(input => data:items) item\n",
    "(FILE_FORMAT => my_json_format);\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **28. Dynamic JSON Key Parsing**\n",
    "\n",
    "```sql\n",
    "SELECT OBJECT_KEYS(data) AS keys\n",
    "FROM @mystage/orders.json\n",
    "(FILE_FORMAT => my_json_format);\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **29. Variant → String Conversion**\n",
    "\n",
    "```sql\n",
    "INSERT INTO customer_flat (customer_name)\n",
    "SELECT data:customer_name::STRING\n",
    "FROM @mystage/customers.json\n",
    "(FILE_FORMAT => my_json_format);\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **30. Combine Semi-structured + Structured Data**\n",
    "\n",
    "```sql\n",
    "INSERT INTO orders_final (order_id, order_date, promo_code)\n",
    "SELECT \n",
    "    o.$1::INT,\n",
    "    TO_DATE(o.$2, 'YYYY-MM-DD'),\n",
    "    j.data:promo_code::STRING\n",
    "FROM @mystage/orders.csv o\n",
    "JOIN @mystage/orders.json j \n",
    "ON o.$1::INT = j.data:order_id::INT\n",
    "(FILE_FORMAT => my_csv_format);\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "✅ **Key Takeaways**:\n",
    "\n",
    "1. Always start from `@stage_name` (internal, table, or external).\n",
    "2. Apply transformations **inside the SELECT** from stage.\n",
    "3. Define proper **file formats** (`FILE_FORMAT`) for CSV, JSON, Parquet.\n",
    "4. Combine **casting, deduplication, cleansing, SCD handling, JSON parsing, joins** to make data analytics-ready.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db3f640",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## **1. Staging Files Are Queryable**\n",
    "\n",
    "* When you upload files to a **stage** (`@stage_name`), they’re **not yet “real tables”**.\n",
    "* But you **can query them using `SELECT`** with the proper `FILE_FORMAT`.\n",
    "\n",
    "Example:\n",
    "\n",
    "```sql\n",
    "SELECT $1::INT AS order_id, $2::STRING AS customer\n",
    "FROM @mystage/orders.csv\n",
    "(FILE_FORMAT => my_csv_format);\n",
    "```\n",
    "\n",
    "* `$1, $2` → column placeholders in the staged file\n",
    "* You can cast, clean, trim, convert dates, apply regex — **all standard transformations**\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Almost All Table Transformations Work**\n",
    "\n",
    "You can do things like:\n",
    "\n",
    "* `CAST` / `::TYPE` conversions\n",
    "* `TRIM`, `UPPER`, `LOWER`, `REGEXP_REPLACE`\n",
    "* `COALESCE`, `NULLIF`\n",
    "* `DATE`/`TIME` functions (`TO_DATE`, `DATEADD`, `DATEDIFF`)\n",
    "* Aggregations (`SUM`, `COUNT`, `AVG`)\n",
    "* Window functions (`ROW_NUMBER`, `RANK`)\n",
    "* Conditional transformations (`CASE`, `IFF`)\n",
    "* JSON/VARIANT processing (`data:field::STRING`)\n",
    "* Flatten arrays (`LATERAL FLATTEN`)\n",
    "\n",
    "✅ In short: **any SQL operation you can do on a table, you can do on staged data before loading it**.\n",
    "\n",
    "---\n",
    "\n",
    "## **3. The Only Differences**\n",
    "\n",
    "| Feature            | Staging                                                        | Table                                                      |\n",
    "| ------------------ | -------------------------------------------------------------- | ---------------------------------------------------------- |\n",
    "| Persistent indexes | ❌ No                                                           | ✅ Yes                                                      |\n",
    "| Constraints        | ❌ No (except semi-enforced)                                    | ✅ Yes                                                      |\n",
    "| Updates / Deletes  | ❌ Not directly (must `COPY INTO` table first)                  | ✅ Yes                                                      |\n",
    "| Metadata           | ✅ Can use `$FILENAME`, `$FILE_ROW_NUMBER`                      | ✅ Table metadata available                                 |\n",
    "| Query performance  | ⚡ Reads directly from staged file; may be slower on huge files | ⚡ Snowflake tables use columnar storage + micro-partitions |\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Practical Workflow**\n",
    "\n",
    "1. **Stage the raw files** (`PUT @mystage/file.csv`)\n",
    "2. **Transform while reading**:\n",
    "\n",
    "```sql\n",
    "SELECT \n",
    "    CAST($1 AS INT) AS order_id,\n",
    "    TO_DATE($2, 'YYYY-MM-DD') AS order_date,\n",
    "    UPPER($3) AS country\n",
    "FROM @mystage/file.csv\n",
    "(FILE_FORMAT => my_csv_format);\n",
    "```\n",
    "\n",
    "3. **Insert into target table** (optional: dedupe, SCD, enrichment)\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ Key Takeaway\n",
    "\n",
    "* **Transformation on staging = Preprocessing before table load.**\n",
    "* This saves **compute**, avoids loading **bad/dirty data**, and lets you handle **huge files incrementally**.\n",
    "* Once data is loaded into a **Snowflake table**, you gain **full SQL capabilities**, indexing, partitioning, and better query performance.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86fe6578",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
