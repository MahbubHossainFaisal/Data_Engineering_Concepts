{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a643f49",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "# 🌟 Understanding Snowflake Tasks: The Story of “Daily Sales ETL Automation”\n",
    "\n",
    "Imagine you’re working in **IQVIA**, where your Snowflake warehouse stores **sales data from multiple regions**.\n",
    "Every night, new sales files land in an **S3 bucket**, loaded into a **raw staging table** through a **Snowpipe**.\n",
    "Now, once that data arrives, you want to:\n",
    "\n",
    "1. **Transform** it (cleaning, aggregating, joining, etc.)\n",
    "2. **Load** it into your **analytics-ready fact table**\n",
    "3. **Update reports** every morning at 6 AM\n",
    "\n",
    "But you face one problem —\n",
    "you don’t want to log in every night at 2 AM to run `INSERT INTO ... SELECT ...`. 😴\n",
    "\n",
    "That’s where **Snowflake Tasks** come to the rescue.\n",
    "\n",
    "---\n",
    "\n",
    "## 🧠 What Are Snowflake Tasks?\n",
    "\n",
    "> A **Task** in Snowflake is a *scheduled* SQL operation (or series of operations) that runs automatically — similar to a **cron job** or **Airflow DAG**, but *natively inside Snowflake*.\n",
    "\n",
    "✅ You can use it to:\n",
    "\n",
    "* Schedule SQL statements (like INSERT, UPDATE, MERGE, CALL procedure)\n",
    "* Automate data pipelines\n",
    "* Create dependencies between tasks (like workflows or DAGs)\n",
    "* Chain tasks for ETL/ELT jobs\n",
    "\n",
    "---\n",
    "\n",
    "## 🎯 Purpose of Tasks\n",
    "\n",
    "The **purpose** of Snowflake Tasks is to **automate data processing workflows** directly inside the Snowflake ecosystem.\n",
    "\n",
    "Without tasks, you’d need:\n",
    "\n",
    "* An external scheduler (Airflow, Azure Data Factory, etc.)\n",
    "* Custom scripts to trigger SQL commands\n",
    "\n",
    "With **tasks**, you can:\n",
    "\n",
    "* Schedule recurring SQL logic inside Snowflake itself\n",
    "* Reduce dependency on external orchestrators\n",
    "* Control and monitor workflows easily using **TASK HISTORY**\n",
    "\n",
    "---\n",
    "\n",
    "## 🚨 The Problem They Solve\n",
    "\n",
    "Let’s take our scenario again.\n",
    "\n",
    "### Before Tasks\n",
    "\n",
    "You had to:\n",
    "\n",
    "* Write SQL transformations manually\n",
    "* Run them daily using Airflow, or manually\n",
    "* Monitor failures via external tools\n",
    "\n",
    "### After Tasks\n",
    "\n",
    "Now you can:\n",
    "\n",
    "* Schedule Snowflake to automatically run your ETL SQL\n",
    "* Chain multiple steps (load → transform → aggregate → report refresh)\n",
    "* View logs using **TASK_HISTORY**\n",
    "* Automatically pause, resume, or reschedule when needed\n",
    "\n",
    "You’ve just automated your data pipeline *within Snowflake* — no external dependency.\n",
    "\n",
    "---\n",
    "\n",
    "## ⚙️ How to Create a Task — Step by Step\n",
    "\n",
    "Let’s build one for our “Daily Sales ETL”.\n",
    "\n",
    "### 🧩 Step 1: Create the Task\n",
    "\n",
    "```sql\n",
    "CREATE OR REPLACE TASK DAILY_SALES_ETL_TASK\n",
    "  WAREHOUSE = COMPUTE_WH\n",
    "  SCHEDULE = 'USING CRON 0 6 * * * Asia/Dhaka'\n",
    "  AS\n",
    "  INSERT INTO FACT_SALES (SELECT * FROM STAGING_SALES WHERE LOAD_DATE = CURRENT_DATE());\n",
    "```\n",
    "\n",
    "### 🧠 Explanation\n",
    "\n",
    "| Clause                        | Description                                                                 |\n",
    "| ----------------------------- | --------------------------------------------------------------------------- |\n",
    "| `CREATE OR REPLACE TASK`      | Defines a new task                                                          |\n",
    "| `WAREHOUSE = COMPUTE_WH`      | Specifies which warehouse will run the SQL                                  |\n",
    "| `SCHEDULE = 'USING CRON ...'` | Defines when it runs (like cronjob syntax)                                  |\n",
    "| `AS`                          | The actual SQL logic (can be `INSERT`, `MERGE`, `CALL` a stored proc, etc.) |\n",
    "\n",
    "This means every day at **6 AM (Dhaka time)**, this task will:\n",
    "\n",
    "* Wake up the **COMPUTE_WH** warehouse\n",
    "* Run the SQL inside it\n",
    "* Load daily sales data into your fact table\n",
    "\n",
    "---\n",
    "\n",
    "## 🕒 Scheduling a Task\n",
    "\n",
    "You can schedule using two formats:\n",
    "\n",
    "### 1️⃣ Using CRON\n",
    "\n",
    "```sql\n",
    "SCHEDULE = 'USING CRON 0 6 * * * Asia/Dhaka'\n",
    "```\n",
    "\n",
    "→ Runs daily at 6 AM Dhaka time.\n",
    "\n",
    "### 2️⃣ Using INTERVAL\n",
    "\n",
    "```sql\n",
    "SCHEDULE = '1 HOUR'\n",
    "```\n",
    "\n",
    "→ Runs every 1 hour after last successful execution.\n",
    "\n",
    "---\n",
    "\n",
    "## 💤 Suspending a Task\n",
    "\n",
    "Sometimes you need to pause a task temporarily — maybe for maintenance or debugging.\n",
    "\n",
    "```sql\n",
    "ALTER TASK DAILY_SALES_ETL_TASK SUSPEND;\n",
    "```\n",
    "\n",
    "To resume:\n",
    "\n",
    "```sql\n",
    "ALTER TASK DAILY_SALES_ETL_TASK RESUME;\n",
    "```\n",
    "\n",
    "🧩 *Tip:*\n",
    "When you create a task, it starts in **SUSPENDED** state by default.\n",
    "You need to **resume** it to activate.\n",
    "\n",
    "---\n",
    "\n",
    "## 📜 Checking Task History\n",
    "\n",
    "To check when and how a task ran:\n",
    "\n",
    "```sql\n",
    "SELECT *\n",
    "FROM TABLE(INFORMATION_SCHEMA.TASK_HISTORY(\n",
    "  TASK_NAME => 'DAILY_SALES_ETL_TASK',\n",
    "  RESULT_LIMIT => 10\n",
    "));\n",
    "```\n",
    "\n",
    "This will show:\n",
    "\n",
    "* Run start & end time\n",
    "* Status (SUCCESS / FAILED)\n",
    "* Query ID (to trace in query history)\n",
    "* Error message (if any)\n",
    "\n",
    "✅ Perfect for debugging and monitoring.\n",
    "\n",
    "---\n",
    "\n",
    "## 🧩 Creating a Task Workflow (Task Dependency)\n",
    "\n",
    "Here’s where things get exciting.\n",
    "Snowflake allows **dependent tasks**, where one task triggers **another** after it finishes successfully.\n",
    "\n",
    "Imagine this flow:\n",
    "\n",
    "```\n",
    "RAW → STAGING → FACT → REPORT\n",
    "```\n",
    "\n",
    "Each arrow means:\n",
    "\n",
    "* When RAW load completes, STAGING starts\n",
    "* When STAGING completes, FACT starts\n",
    "* When FACT completes, REPORT updates\n",
    "\n",
    "We can model that in Snowflake.\n",
    "\n",
    "---\n",
    "\n",
    "### 🧠 Step 1: Create the Root Task\n",
    "\n",
    "```sql\n",
    "CREATE OR REPLACE TASK LOAD_RAW_SALES\n",
    "  WAREHOUSE = COMPUTE_WH\n",
    "  SCHEDULE = 'USING CRON 0 2 * * * Asia/Dhaka'\n",
    "  AS\n",
    "  INSERT INTO RAW_SALES\n",
    "  SELECT * FROM EXTERNAL_STAGE;\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 🧠 Step 2: Create a Child Task (Depends On Parent)\n",
    "\n",
    "```sql\n",
    "CREATE OR REPLACE TASK TRANSFORM_STAGING\n",
    "  WAREHOUSE = COMPUTE_WH\n",
    "  AFTER LOAD_RAW_SALES\n",
    "  AS\n",
    "  INSERT INTO STAGING_SALES\n",
    "  SELECT * FROM RAW_SALES WHERE LOAD_DATE = CURRENT_DATE();\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 🧠 Step 3: Another Child Task (Chain Further)\n",
    "\n",
    "```sql\n",
    "CREATE OR REPLACE TASK AGGREGATE_FACT\n",
    "  WAREHOUSE = COMPUTE_WH\n",
    "  AFTER TRANSFORM_STAGING\n",
    "  AS\n",
    "  INSERT INTO FACT_SALES\n",
    "  SELECT REGION, SUM(SALES_AMOUNT)\n",
    "  FROM STAGING_SALES\n",
    "  GROUP BY REGION;\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 🧠 Step 4: Final Task for Reporting\n",
    "\n",
    "```sql\n",
    "CREATE OR REPLACE TASK REFRESH_REPORTS\n",
    "  WAREHOUSE = COMPUTE_WH\n",
    "  AFTER AGGREGATE_FACT\n",
    "  AS\n",
    "  CALL REFRESH_DAILY_REPORT();\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 🧭 Graph Visualization of the Workflow\n",
    "\n",
    "Here’s the logical **Task Graph**:\n",
    "\n",
    "```\n",
    "          ┌──────────────────┐\n",
    "          │  LOAD_RAW_SALES  │  (Root Task)\n",
    "          └────────┬─────────┘\n",
    "                   ↓\n",
    "         ┌────────────────────┐\n",
    "         │ TRANSFORM_STAGING  │\n",
    "         └────────┬───────────┘\n",
    "                   ↓\n",
    "         ┌────────────────────┐\n",
    "         │  AGGREGATE_FACT    │\n",
    "         └────────┬───────────┘\n",
    "                   ↓\n",
    "         ┌────────────────────┐\n",
    "         │  REFRESH_REPORTS   │\n",
    "         └────────────────────┘\n",
    "```\n",
    "\n",
    "👉 The flow automatically continues once each parent finishes successfully.\n",
    "👉 You only need to **schedule the root task**, others are triggered automatically.\n",
    "\n",
    "---\n",
    "\n",
    "## 🧩 Task Dependency Behavior\n",
    "\n",
    "| Concept              | Description                                                                 |\n",
    "| -------------------- | --------------------------------------------------------------------------- |\n",
    "| **Root Task**        | Has a schedule defined                                                      |\n",
    "| **Child Task**       | Uses `AFTER` clause to define dependency                                    |\n",
    "| **Failure Handling** | Child tasks only run if parent succeeds                                     |\n",
    "| **Graph Limit**      | One root can have multiple children, forming a DAG (Directed Acyclic Graph) |\n",
    "\n",
    "---\n",
    "\n",
    "## ⚡️ Most Used Variations of Tasks\n",
    "\n",
    "| Task Type                     | Description                             | Example                                   |\n",
    "| ----------------------------- | --------------------------------------- | ----------------------------------------- |\n",
    "| **Single Task**               | Independent scheduled SQL               | Daily ETL job                             |\n",
    "| **Chained Tasks (Workflow)**  | Dependent tasks forming DAG             | Multi-step ETL                            |\n",
    "| **Procedure Task**            | Calls a stored procedure                | `AS CALL my_procedure();`                 |\n",
    "| **Continuous Task**           | Runs based on parent task completion    | `AFTER parent_task`                       |\n",
    "| **Stream + Task Combination** | Automates incremental load from streams | Use `SELECT * FROM my_stream` inside task |\n",
    "\n",
    "---\n",
    "\n",
    "## 🔍 Real-World Example — Stream + Task\n",
    "\n",
    "You have a stream that captures changes from `STG_CUSTOMER`.\n",
    "You want those changes to be automatically merged into your `DIM_CUSTOMER` table.\n",
    "\n",
    "```sql\n",
    "CREATE OR REPLACE TASK CUSTOMER_DIM_UPSERT\n",
    "  WAREHOUSE = COMPUTE_WH\n",
    "  SCHEDULE = '1 HOUR'\n",
    "  AS\n",
    "  MERGE INTO DIM_CUSTOMER d\n",
    "  USING STG_CUSTOMER_STREAM s\n",
    "  ON d.CUST_ID = s.CUST_ID\n",
    "  WHEN MATCHED THEN UPDATE SET ...\n",
    "  WHEN NOT MATCHED THEN INSERT (...);\n",
    "```\n",
    "\n",
    "This ensures every hour your dimension table stays up-to-date.\n",
    "\n",
    "---\n",
    "\n",
    "## 💡 Pro Tips\n",
    "\n",
    "1. **Monitor using TASK_HISTORY** and **QUERY_HISTORY**\n",
    "2. **Use stored procedures** for complex multi-step SQL logic\n",
    "3. **Always test manually before scheduling**\n",
    "4. **Check task status** in UI: `SHOW TASKS;`\n",
    "5. **Warehouse suspension:**\n",
    "   If warehouse is suspended, Snowflake auto-resumes it when task runs\n",
    "6. **Error retries:**\n",
    "   Tasks automatically retry 3 times before marking as FAILED\n",
    "\n",
    "---\n",
    "\n",
    "## 🧩 Commonly Asked Questions (Must Know)\n",
    "\n",
    "1. **Can a task call another task directly?**\n",
    "   → No. Only via dependency (`AFTER`).\n",
    "\n",
    "2. **What happens if parent task fails?**\n",
    "   → Child task won’t run.\n",
    "\n",
    "3. **Can multiple tasks depend on one parent?**\n",
    "   → Yes, that creates a branching DAG.\n",
    "\n",
    "4. **Can we alter schedule or SQL of a task?**\n",
    "   → Yes, using `ALTER TASK` commands.\n",
    "\n",
    "5. **Can a task run a stored procedure?**\n",
    "   → Absolutely, and that’s very common in production ETL.\n",
    "\n",
    "6. **Where can I see all tasks?**\n",
    "   → `SHOW TASKS;`\n",
    "\n",
    "7. **What happens if a task runs long?**\n",
    "   → It runs independently; next scheduled run won’t start until current finishes.\n",
    "\n",
    "---\n",
    "\n",
    "## 🧭 Summary\n",
    "\n",
    "| Concept          | Description                                               |\n",
    "| ---------------- | --------------------------------------------------------- |\n",
    "| **Purpose**      | Automate and schedule SQL workflows in Snowflake          |\n",
    "| **Benefit**      | No external orchestration needed                          |\n",
    "| **Scheduling**   | CRON or INTERVAL                                          |\n",
    "| **Dependencies** | Created with `AFTER` clause                               |\n",
    "| **Monitoring**   | `INFORMATION_SCHEMA.TASK_HISTORY`                         |\n",
    "| **Use Cases**    | ETL automation, incremental loads, data refresh pipelines |\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1190f792",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
